{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/naorko/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/naorko/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    " \n",
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Concatenate\n",
    "from tensorflow.keras.layers import Dropout, Dense, Lambda, Multiply, Subtract, Flatten\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Activation, Reshape\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Text preprocessing\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Plots\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Misc.\n",
    "import os\n",
    "import joblib\n",
    "import random\n",
    "import time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pretty_midi\n",
    "\n",
    "SEED = 42\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Singer', 'Song Name', 'Lyrics']\n",
    "\n",
    "df = pd.read_csv('datasets/lyrics_train_set.csv', names=cols)\n",
    "df_test = pd.read_csv('datasets/lyrics_test_set.csv', names=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove non rational lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Singer</th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>darude</td>\n",
       "      <td>sandstorm</td>\n",
       "      <td>[instrumental] &amp; du du dudududududuud &amp; dududu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Singer  Song Name                                             Lyrics\n",
       "315  darude  sandstorm  [instrumental] & du du dudududududuud & dududu..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_song = df.query(\"Singer == 'darude'\")\n",
    "bad_song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(axis=0, index=bad_song.index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add midi files' names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_midi_files(df):\n",
    "    midis = list(os.listdir(r'./datasets/midi_files'))\n",
    "    midis = {midi.lower()[:-4]: midi for midi in midis}    \n",
    "    \n",
    "    def combine_singer_song(singer, song):\n",
    "        key = f'{singer} - {song}'.replace(' ', '_').lower()\n",
    "        return midis[key] if key in midis else None\n",
    "    \n",
    "    df['Midi File'] = df.apply(lambda r: combine_singer_song(r['Singer'], r['Song Name']) ,axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_midi_files(df)\n",
    "df_test = add_midi_files(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check midi files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(619,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "midis = np.concatenate([df['Midi File'].values, df_test['Midi File'].values])\n",
    "midis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naorko/.conda/envs/tf-env/lib/python3.8/site-packages/pretty_midi/pretty_midi.py:97: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not decode key with 16 sharps and mode 1\n",
      "error readying midi file David_Bowie_-_Lazarus.mid\n",
      "Could not decode key with 1 flats and mode 255\n",
      "error readying midi file Beastie_Boys_-_Girls.mid\n",
      "data byte must be in range 0..127\n",
      "error readying midi file Billy_Joel_-_Movin'_Out.mid\n",
      "data byte must be in range 0..127\n",
      "error readying midi file Billy_Joel_-_Pressure.mid\n",
      "Could not decode key with 4 flats and mode 255\n",
      "error readying midi file Dan_Fogelberg_-_Leader_of_the_Band.mid\n",
      "\n",
      "error readying midi file Brian_McKnight_-_On_The_Down_Low.mid\n",
      "data byte must be in range 0..127\n",
      "error readying midi file Aaron_Neville_-_Tell_It_Like_It_Is.mid\n"
     ]
    }
   ],
   "source": [
    "corrupted = []\n",
    "for i, midi in enumerate(midis):\n",
    "    try:\n",
    "        midi = pretty_midi.PrettyMIDI(fr'./datasets/midi_files/{midi}')\n",
    "        midi.remove_invalid_notes()\n",
    "        del midi\n",
    "    except Exception as e:\n",
    "        print(\"%s\\nerror readying midi file %s\" % (e, midi))\n",
    "        corrupted.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Singer</th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Midi File</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>david bowie</td>\n",
       "      <td>lazarus</td>\n",
       "      <td>look up here i'm in heaven &amp; i've got scars th...</td>\n",
       "      <td>David_Bowie_-_Lazarus.mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>beastie boys</td>\n",
       "      <td>girls</td>\n",
       "      <td>girls all i really want is girls &amp; and in the ...</td>\n",
       "      <td>Beastie_Boys_-_Girls.mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>billy joel</td>\n",
       "      <td>movin' out</td>\n",
       "      <td>anthony works in the grocery store   &amp; savin h...</td>\n",
       "      <td>Billy_Joel_-_Movin'_Out.mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>billy joel</td>\n",
       "      <td>pressure</td>\n",
       "      <td>you have to learn to pace yourself &amp; pressure ...</td>\n",
       "      <td>Billy_Joel_-_Pressure.mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>dan fogelberg</td>\n",
       "      <td>leader of the band</td>\n",
       "      <td>an only child alone and wild a cabinet maker's...</td>\n",
       "      <td>Dan_Fogelberg_-_Leader_of_the_Band.mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>brian mcknight</td>\n",
       "      <td>on the down low</td>\n",
       "      <td>maxine was 5'9'' &amp; had a man and she didn't mi...</td>\n",
       "      <td>Brian_McKnight_-_On_The_Down_Low.mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>aaron neville</td>\n",
       "      <td>tell it like it is</td>\n",
       "      <td>if you want something to play with &amp; go and fi...</td>\n",
       "      <td>Aaron_Neville_-_Tell_It_Like_It_Is.mid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Singer           Song Name  \\\n",
       "91      david bowie             lazarus   \n",
       "115    beastie boys               girls   \n",
       "136      billy joel          movin' out   \n",
       "143      billy joel            pressure   \n",
       "189   dan fogelberg  leader of the band   \n",
       "513  brian mcknight     on the down low   \n",
       "575   aaron neville  tell it like it is   \n",
       "\n",
       "                                                Lyrics  \\\n",
       "91   look up here i'm in heaven & i've got scars th...   \n",
       "115  girls all i really want is girls & and in the ...   \n",
       "136  anthony works in the grocery store   & savin h...   \n",
       "143  you have to learn to pace yourself & pressure ...   \n",
       "189  an only child alone and wild a cabinet maker's...   \n",
       "513  maxine was 5'9'' & had a man and she didn't mi...   \n",
       "575  if you want something to play with & go and fi...   \n",
       "\n",
       "                                  Midi File  \n",
       "91                David_Bowie_-_Lazarus.mid  \n",
       "115                Beastie_Boys_-_Girls.mid  \n",
       "136             Billy_Joel_-_Movin'_Out.mid  \n",
       "143               Billy_Joel_-_Pressure.mid  \n",
       "189  Dan_Fogelberg_-_Leader_of_the_Band.mid  \n",
       "513    Brian_McKnight_-_On_The_Down_Low.mid  \n",
       "575  Aaron_Neville_-_Tell_It_Like_It_Is.mid  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_songs = df.iloc[corrupted]\n",
    "bad_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(axis=0, index=bad_songs.index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = np.random.rand(len(df)) < 0.8\n",
    "\n",
    "df_train = df[msk]\n",
    "df_val = df[~msk]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lyrics preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    phrase = re.sub(r\"in\\'\", \"ing\", phrase)\n",
    "    phrase = re.sub(r\"y\\'all\", \"you all\", phrase)\n",
    "    \n",
    "    # punctions\n",
    "    regex = re.compile('[^a-zA-Z& ]')\n",
    "    phrase = regex.sub('', phrase)\n",
    "    \n",
    "    return phrase\n",
    "\n",
    "def preprocess_lyrics(data):\n",
    "    data = decontracted(data)\n",
    "    tokens = word_tokenize(data)\n",
    "    data_arr = []\n",
    "    \n",
    "    for t in tokens:\n",
    "        # Use only words, character combinations and numbers \n",
    "#         if not t.isalpha(): \n",
    "#             continue\n",
    "            \n",
    "        # Lower case word\n",
    "        t = t.lower()\n",
    "        \n",
    "#         # Remove stop words\n",
    "#         if t in sw: \n",
    "#             continue\n",
    "        \n",
    "        data_arr.append(t)\n",
    "    \n",
    "    \n",
    "    return data_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"winding your way down on baker street & lite in your head and dead on your feet & well another crazy day you drink the night away & and forget about everything & this city desert makes you feel so cold & its got so many people but its got no soul & and it's taken you so long to find out you were wrong & when you thought it held everything. & you used to think that it was so easy & you used to say that it was so easy & but you're tryin you're tryin now & another year and then you'd be happy & just one more year and then you'd be happy & but you're cryin' you're cryin' now & way down the street there's a light in his place & you open the door he's got that look on his face & and he asks you where you've been you tell him who you've seen & and you talk about anything & he's got this dream about buyin' some land & he's gonna give up the booze and the one night stands & and then he'll settle down it's a quiet little town & and forget about everything & but you know he'll always keep moving & you know he's never gonna stop moving & 'cause he's rollin & he's the rolling stone & and when you wake up it's a new morning & the sun is shining it's a new morning & and you're going you're going home &\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.iloc[1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "winding your way down on baker street \n",
      "\n",
      "lite in your head and dead on your feet \n",
      "\n",
      "well another crazy day you drink the night away \n",
      "\n",
      "and forget about everything \n",
      "\n",
      "this city desert makes you feel so cold \n",
      "\n",
      "its got so many people but its got no soul \n",
      "\n",
      "and it is taken you so long to find out you were wrong \n",
      "\n",
      "when you thought it held everything \n",
      "\n",
      "you used to think that it was so easy \n",
      "\n",
      "you used to say that it was so easy \n",
      "\n",
      "but you are tryin you are tryin now \n",
      "\n",
      "another year and then you would be happy \n",
      "\n",
      "just one more year and then you would be happy \n",
      "\n",
      "but you are crying you are crying now \n",
      "\n",
      "way down the street there is a light in his place \n",
      "\n",
      "you open the door he is got that look on his face \n",
      "\n",
      "and he asks you where you have been you tell him who you have seen \n",
      "\n",
      "and you talk about anything \n",
      "\n",
      "he is got this dream about buying some land \n",
      "\n",
      "he is gon na give up the booze and the one night stands \n",
      "\n",
      "and then he will settle down it is a quiet little town \n",
      "\n",
      "and forget about everything \n",
      "\n",
      "but you know he will always keep moving \n",
      "\n",
      "you know he is never gon na stop moving \n",
      "\n",
      "cause he is rollin \n",
      "\n",
      "he is the rolling stone \n",
      "\n",
      "and when you wake up it is a new morning \n",
      "\n",
      "the sun is shining it is a new morning \n",
      "\n",
      "and you are going you are going home \n",
      "\n"
     ]
    }
   ],
   "source": [
    "string = df_train.iloc[1,2]\n",
    "tokenized_string = preprocess_lyrics(string)\n",
    "\n",
    "def pretty_lyrics(tokenized_string):\n",
    "    for token in tokenized_string:\n",
    "        if token == '&':\n",
    "            print('\\n')\n",
    "        else:\n",
    "            print(token, end=' ')\n",
    "\n",
    "pretty_lyrics(tokenized_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_token = '$'\n",
    "lyrics_train = df_train['Lyrics'].apply(lambda s: preprocess_lyrics(s)[:-1] + [stop_token])\n",
    "lyrics_val = df_val['Lyrics'].apply(lambda s: preprocess_lyrics(s)[:-1] + [stop_token])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(lyrics_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_train = tokenizer.texts_to_sequences(lyrics_train)\n",
    "lyrics_val = tokenizer.texts_to_sequences(lyrics_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_FILE = './GoogleNews-vectors-negative300.bin'\n",
    "\n",
    "if not os.path.isfile(EMBEDDING_FILE):\n",
    "    !wget -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\"\n",
    "    !gzip -f -d GoogleNews-vectors-negative300.bin.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505 out of 6366 has no embedings from word2vec\n"
     ]
    }
   ],
   "source": [
    "from gensim import models\n",
    "\n",
    "embeddings_index = models.KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)\n",
    "embed_size = 300\n",
    "word_index = tokenizer.word_index\n",
    "max_features = len(word_index) + 1\n",
    "\n",
    "nb_words = len(word_index)\n",
    "embedding_matrix = (np.random.rand(nb_words+1, embed_size) - 0.5) / 5.0\n",
    "\n",
    "not_in_word2vec = 0\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    if word in embeddings_index:\n",
    "        embedding_vector = embeddings_index.get_vector(word)\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    else:\n",
    "        not_in_word2vec += 1\n",
    "        \n",
    "print(f'{not_in_word2vec} out of {len(word_index)} has no embedings from word2vec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying one word to whole song but one word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x, train_y = [], []\n",
    "\n",
    "# for lyric in lyrics:\n",
    "#     for i in range(1, len(lyric)):\n",
    "#         train_x.append(lyric[:i])\n",
    "#         train_y.append(*lyric[i:i+1])\n",
    "        \n",
    "# train_x = pad_sequences(train_x)\n",
    "# train_y = to_categorical(train_y)\n",
    "# train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying sliding window of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ast=np.lib.index_tricks.as_strided\n",
    "def generate_sliding_window(arr, window_size=5, window_stride=1, last_window=False):\n",
    "    last_window = 1 if last_window else 0\n",
    "    arr = np.ascontiguousarray(arr)\n",
    "    arr_len = arr.shape[0]\n",
    "    s, = arr.strides\n",
    "    windows_num = ((arr_len-window_size)//window_stride) + last_window\n",
    "    \n",
    "    return ast(arr, (windows_num, window_size), (s*window_stride, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_lyrics(lyrics, window_size=10):\n",
    "    X, y = [], []\n",
    "    for lyric in lyrics:\n",
    "        X.append(generate_sliding_window(lyric, window_size))\n",
    "        y.append(to_categorical(lyric[window_size:], num_classes=max_features))\n",
    "        \n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 10\n",
    "lyrics_train = split_lyrics(lyrics_train, window_size)\n",
    "lyrics_val = split_lyrics(lyrics_val, window_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Melody preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ast=np.lib.index_tricks.as_strided\n",
    "def generate_sliding_window_2d(arr, window_size=5, window_stride=1, last_window=False):\n",
    "    last_window = 1 if last_window else 0\n",
    "    arr = np.ascontiguousarray(arr)\n",
    "    l0, l1 = arr.shape\n",
    "    s0, s1 = arr.strides\n",
    "    windows_num = ((l0-window_size)//window_stride) + last_window\n",
    "    \n",
    "    return ast(arr, (windows_num, window_size, l1), (s0*window_stride, s0, s1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_melody_file_by_time(midi_name, fs=5, max_piano_val=100, fpw=4, window_size=10):\n",
    "    pm = pretty_midi.PrettyMIDI(fr'./datasets/midi_files/{midi_name}')\n",
    "    pm.remove_invalid_notes()\n",
    "    \n",
    "    # Sum all notes from all instruments\n",
    "    piano_all = pm.get_piano_roll(fs=fs)\n",
    "    piano_shape = piano_all.shape\n",
    "\n",
    "    # Normalize by the number of played instruments in the same time and note\n",
    "    counter = np.zeros(piano_shape)\n",
    "    for inst in pm.instruments:\n",
    "        curr_piano = inst.get_piano_roll(fs=fs)\n",
    "\n",
    "        counter[:, :curr_piano.shape[1]] += (curr_piano > 0).astype(int)\n",
    "\n",
    "    counter[counter == 0] = 1\n",
    "    piano_all /= counter\n",
    "    \n",
    "    # Normalize by the maximum value of a note\n",
    "    piano_all = piano_all / max_piano_val\n",
    "    \n",
    "    # Normalize by the number of played notes in the same time\n",
    "    count_notes = (piano_all > 0).sum(axis=0)\n",
    "    count_notes[count_notes == 0] = 1\n",
    "    melody = piano_all.sum(axis=0) / count_notes\n",
    "    del piano_all\n",
    "    \n",
    "    # 3 frames of 5fps equal to 0.6s ~ about one word\n",
    "    melody_per_word = generate_sliding_window(melody[(melody > 0).argmax():], window_size=fpw, window_stride=(fpw*2)//5, last_window=True)\n",
    "    melody_windows = generate_sliding_window_2d(melody_per_word, window_size=window_size, last_window=True)\n",
    "    \n",
    "    return melody_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1821bf71fa445ca8f9c1f52b31709ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=612), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The maximum note value is 762.0\n",
      "The minimum song length is 297\n",
      "The maximum song length is 3006\n"
     ]
    }
   ],
   "source": [
    "midis = np.concatenate([df['Midi File'].values, df_test['Midi File'].values])\n",
    "fs = 5\n",
    "\n",
    "max_note_val = -1\n",
    "min_frames = 9999\n",
    "max_frames = -1\n",
    "for midi in tqdm(midis):\n",
    "    pm = pretty_midi.PrettyMIDI(fr'./datasets/midi_files/{midi}')\n",
    "    pm.remove_invalid_notes()\n",
    "    \n",
    "    piano_roll = pm.get_piano_roll(fs=fs)\n",
    "    if piano_roll.shape[1]:\n",
    "        curr_len = piano_roll.shape[1]\n",
    "        min_frames = min(min_frames, curr_len)\n",
    "        max_frames = max(max_frames, curr_len)\n",
    "        \n",
    "    for inst in pm.instruments:\n",
    "        piano_roll = inst.get_piano_roll(fs=fs)\n",
    "        if piano_roll.shape[1]:\n",
    "            curr_max_note = piano_roll.max()\n",
    "            max_note_val = max(max_note_val, curr_max_note)\n",
    "        \n",
    "    del pm\n",
    "\n",
    "print(f'The maximum note value is {max_note_val}')\n",
    "print(f'The minimum song length is {min_frames}')\n",
    "print(f'The maximum song length is {max_frames}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naorko/.conda/envs/tf-env/lib/python3.8/site-packages/pretty_midi/pretty_midi.py:97: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "melody_train = df_train['Midi File'].apply(preprocess_melody_file_by_time, fs=100, max_piano_val=762, fpw=100, window_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(lyrics_train[0])):\n",
    "    mel = melody_train.iloc[i]\n",
    "    lyr = lyrics_train[0][i]\n",
    "    if mel.shape[0] >= lyr.shape[0]:\n",
    "        melody_train.iloc[i] = mel[:lyr.shape[0], :, :]\n",
    "    else:\n",
    "        lyrics_train[0][i] = lyrics_train[0][i][:mel.shape[0], :]\n",
    "        lyrics_train[1][i] = lyrics_train[1][i][:mel.shape[0], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(141426, 10, 100)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(melody_train.values).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(141426, 10)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(lyrics_train[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(141426, 6367)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(lyrics_train[1]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Lyrics Generator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_simple(seq_len):\n",
    "    inp = Input(shape=(seq_len,))\n",
    "    \n",
    "    embd = Embedding(max_features, \n",
    "                      embed_size, \n",
    "                      weights=[embedding_matrix],\n",
    "                      input_length=seq_len,\n",
    "                      name='word_embd')(inp)\n",
    "    \n",
    "    lstm = LSTM(100, return_sequences=True)(embd)\n",
    "    lstm = LSTM(100)(lstm)\n",
    "\n",
    "    X = Dense(100, activation=\"relu\")(lstm)\n",
    "    X = Dropout(0.5)(X)\n",
    "    out = Dense(max_features, activation=\"softmax\", name = 'out')(X)\n",
    "\n",
    "    model = Model(inp, out)\n",
    "    \n",
    "#     model.get_layer('embd').trainable = False\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callbacks(model_name):\n",
    "    acc = 'val_loss'\n",
    "    acc_mode = 'min'\n",
    "    \n",
    "    checkpoint = ModelCheckpoint(\n",
    "                              fr'./models/{model_name}.h5', \n",
    "                              monitor=acc, \n",
    "#                               verbose=1, \n",
    "                              save_best_only=True, \n",
    "                              mode=acc_mode)\n",
    "    earlystop = EarlyStopping(monitor=acc, mode=acc_mode, verbose=1, patience=6)\n",
    "    reduceLR = ReduceLROnPlateau(monitor = 'val_loss', mode = 'min', patience = 5,\n",
    "                            factor = 0.5, min_lr = 1e-6, verbose = 1)\n",
    "\n",
    "    return [checkpoint, reduceLR] #earlystop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_gen, train_data, val_data, use_saved=False, params_dict=None):\n",
    "    os.makedirs('./models', exist_ok=True)\n",
    "    params = ''\n",
    "    if params_dict is not None:\n",
    "        params = '_'.join(f'{key}_{val}' for key,val in params_dict.items())\n",
    "    model_name = model_gen.__name__[5:] + f'_{params}'\n",
    "        \n",
    "    if use_saved:\n",
    "        history = joblib.load(fr'./models/{model_name}_history.sav')\n",
    "    else:\n",
    "        callbacks = get_callbacks(model_name)\n",
    "        \n",
    "        train_x, train_y = train_data\n",
    "        \n",
    "        model = model_gen(train_x.shape[1]) # window size\n",
    "        history = model.fit(\n",
    "                            x=train_x,\n",
    "                            y=train_y,\n",
    "                            batch_size=params_dict['batch_size'],\n",
    "                            epochs=params_dict['epochs'],\n",
    "                            validation_data=val_data,\n",
    "                            callbacks=callbacks,\n",
    "                            verbose=1\n",
    "                            )\n",
    "        \n",
    "        history = history.history\n",
    "        joblib.dump(history, fr'./models/{model_name}_history.sav')\n",
    "    \n",
    "    model = load_model(fr'./models/{model_name}.h5')\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        [(None, 1204)]            0         \n",
      "_________________________________________________________________\n",
      "word_embd (Embedding)        (None, 1204, 300)         1913400   \n",
      "_________________________________________________________________\n",
      "lstm_17 (LSTM)               (None, 1204, 100)         160400    \n",
      "_________________________________________________________________\n",
      "lstm_18 (LSTM)               (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "out (Dense)                  (None, 6378)              644178    \n",
      "=================================================================\n",
      "Total params: 2,808,478\n",
      "Trainable params: 2,808,478\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = init_simple(train_x.shape[1])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4619/4619 [==============================] - 86s 17ms/step - loss: 5.7913 - val_loss: 5.0301\n",
      "Epoch 2/20\n",
      "4619/4619 [==============================] - 70s 15ms/step - loss: 4.9867 - val_loss: 4.8607\n",
      "Epoch 3/20\n",
      "4619/4619 [==============================] - 69s 15ms/step - loss: 4.6565 - val_loss: 4.8774\n",
      "Epoch 4/20\n",
      "4619/4619 [==============================] - 76s 16ms/step - loss: 4.4195 - val_loss: 4.9408\n",
      "Epoch 5/20\n",
      "4619/4619 [==============================] - 76s 16ms/step - loss: 4.2456 - val_loss: 5.0937\n",
      "Epoch 6/20\n",
      "4619/4619 [==============================] - 77s 17ms/step - loss: 4.0573 - val_loss: 5.2618\n",
      "Epoch 7/20\n",
      "4619/4619 [==============================] - 76s 17ms/step - loss: 3.9183 - val_loss: 5.4201\n",
      "Epoch 8/20\n",
      "4619/4619 [==============================] - 76s 16ms/step - loss: 3.7498 - val_loss: 5.7651\n",
      "Epoch 9/20\n",
      "4619/4619 [==============================] - 75s 16ms/step - loss: 3.6126 - val_loss: 5.9113\n",
      "Epoch 10/20\n",
      "4619/4619 [==============================] - 77s 17ms/step - loss: 3.5423 - val_loss: 6.2786\n",
      "Epoch 11/20\n",
      "4619/4619 [==============================] - 77s 17ms/step - loss: 3.4657 - val_loss: 6.6475\n",
      "Epoch 12/20\n",
      "4619/4619 [==============================] - 76s 16ms/step - loss: 3.3858 - val_loss: 6.7223\n",
      "Epoch 13/20\n",
      "4619/4619 [==============================] - 76s 17ms/step - loss: 3.2913 - val_loss: 7.0218\n",
      "Epoch 14/20\n",
      "4619/4619 [==============================] - 76s 16ms/step - loss: 3.2235 - val_loss: 7.2949\n",
      "Epoch 15/20\n",
      "4619/4619 [==============================] - 76s 16ms/step - loss: 3.1806 - val_loss: 7.3991\n",
      "Epoch 16/20\n",
      "4619/4619 [==============================] - 75s 16ms/step - loss: 3.1418 - val_loss: 7.8695\n",
      "Epoch 17/20\n",
      "4619/4619 [==============================] - 76s 16ms/step - loss: 3.1013 - val_loss: 7.8988\n",
      "Epoch 18/20\n",
      "4619/4619 [==============================] - 76s 17ms/step - loss: 3.0494 - val_loss: 8.1687\n",
      "Epoch 19/20\n",
      "4619/4619 [==============================] - 76s 16ms/step - loss: 3.0154 - val_loss: 8.3088\n",
      "Epoch 20/20\n",
      "4619/4619 [==============================] - 76s 16ms/step - loss: 2.9887 - val_loss: 8.4389\n"
     ]
    }
   ],
   "source": [
    "params_dict = {'batch_size': 32, 'epochs': 20}\n",
    "model, history= train_model(init_simple, train_data, val_data, use_saved=F, params_dict=params_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Lyrics by Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_song(model, seed, window_size, stop_token, tokenizer, max_len):\n",
    "    stop_token = tokenizer.word_index[stop_token]\n",
    "    \n",
    "    def get_next_word(seed):\n",
    "        probs = model.predict(seed)\n",
    "        chosen_idx = np.random.choice(range(0, max_features), p=probs[0])\n",
    "        chosen_word = tokenizer.sequences_to_texts([[chosen_idx]])[0]\n",
    "        \n",
    "        return chosen_idx, chosen_word\n",
    "    \n",
    "    \n",
    "    seed = preprocess_lyrics(seed)\n",
    "    song = seed.copy()\n",
    "    seed = ' '.join(seed)\n",
    "    seed = tokenizer.texts_to_sequences([seed])\n",
    "    seed = pad_sequences(seed, maxlen=window_size)\n",
    "\n",
    "    i = 0\n",
    "    idx, word = get_next_word(seed)\n",
    "    while word != stop_token and i < max_len:\n",
    "        song.append(word)\n",
    "        i+=1\n",
    "        seed = np.concatenate([seed[:,1:], [[idx]]], axis=1)\n",
    "        idx, word = get_next_word(seed)\n",
    "    \n",
    "    return song    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_max_length = 2000\n",
    "seed = 'Smack that all on the floor'\n",
    "song = generate_song(model, seed, window_size, stop_token, tokenizer, song_max_length)\n",
    "pretty_lyrics(song)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-env)",
   "language": "python",
   "name": "tf-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
