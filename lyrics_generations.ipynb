{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    " \n",
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Concatenate\n",
    "from tensorflow.keras.layers import Dropout, Dense, Lambda, Multiply, Subtract, Flatten\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Activation, Reshape\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Text preprocessing\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Plots\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Misc.\n",
    "import os\n",
    "import joblib\n",
    "import random\n",
    "import time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pretty_midi\n",
    "\n",
    "SEED = 42\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/liavba/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/liavba/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/liavba/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Singer', 'Song Name', 'Lyrics']\n",
    "df_train = pd.read_csv('datasets/lyrics_train_set.csv', names=cols)\n",
    "\n",
    "# df_test = pd.read_csv('datasets/lyrics_test_set.csv', names=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pretty_midi.pretty_midi.PrettyMIDI at 0x7fdf0fc7ce10>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm = pretty_midi.PrettyMIDI('datasets/midi_files/aladdin_-_A_whole_new_world.mid')\n",
    "pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 time signature changes\n",
      "There are 9 instruments\n",
      "Instrument 3 has 227 notes\n",
      "Instrument 4 has 0 pitch bends\n",
      "Instrument 5 has 0 control changes\n"
     ]
    }
   ],
   "source": [
    "print('There are {} time signature changes'.format(len(pm.time_signature_changes)))\n",
    "print('There are {} instruments'.format(len(pm.instruments)))\n",
    "print('Instrument 3 has {} notes'.format(len(pm.instruments[0].notes)))\n",
    "print('Instrument 4 has {} pitch bends'.format(len(pm.instruments[4].pitch_bends)))\n",
    "print('Instrument 5 has {} control changes'.format(len(pm.instruments[5].control_changes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'goodbye norma jean & though i never knew you at all & you had the grace to hold yourself & while those around you crawled & they crawled out of the woodwork & and they whispered into your brain & they set you on the treadmill & and they made you change your name & and it seems to me you lived your life & like a candle in the wind & never knowing who to cling to & when the rain set in & and i would liked to have known you & but i was just a kid & your candle burned out long before & your legend ever did & loneliness was tough & the toughest role you ever played & hollywood created a superstar & and pain was the price you paid & even when you died & oh the press still hounded you & all the papers had to say & was that marilyn was found in the nude & and it seems to me you lived your life & like a candle in the wind & never knowing who to cling to & when the rain set in & and i would liked to have known you & but i was just a kid & your candle burned out long before & your legend ever did & goodbye norma jean & though i never knew you at all & you had the grace to hold yourself & while those around you crawled & goodbye norma jean & from the young man in the twenty second row & who sees you as something as more than sexual & more than just our marilyn monroe & and it seems to me you lived your life & like a candle in the wind & never knowing who to cling to & when the rain set in & and i would liked to have known you & but i was just a kid & your candle burned out long before & your legend ever did & the candle burned out long before & your legend ever did &'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = df_train.iloc[0, 2]\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    phrase = re.sub(r\"in\\'\", \"ing\", phrase)\n",
    "    phrase = re.sub(r\"y\\'all\", \"you all\", phrase)\n",
    "    \n",
    "    # punctions\n",
    "    regex = re.compile('[^a-zA-Z& ]')\n",
    "    phrase = regex.sub('', phrase)\n",
    "    \n",
    "    return phrase\n",
    "\n",
    "def preprocess_lyrics(data):\n",
    "    data = decontracted(data)\n",
    "    tokens = word_tokenize(data)\n",
    "    data_arr = []\n",
    "    \n",
    "    for t in tokens:\n",
    "        # Use only words, character combinations and numbers \n",
    "#         if not t.isalpha(): \n",
    "#             continue\n",
    "            \n",
    "        # Lower case word\n",
    "        t = t.lower()\n",
    "        \n",
    "#         # Remove stop words\n",
    "#         if t in sw: \n",
    "#             continue\n",
    "        \n",
    "        data_arr.append(t)\n",
    "    \n",
    "    \n",
    "    return data_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[chorus:]   & oh i'm bein' followed by a moonshadow moon shadow moonshadow---   & leapin and hoppin' on a moonshadow moonshadow moonshadow---   &    & and if i ever lose my hands lose my plough lose my land   & oh if i ever lose my hands oh if i won't have to work no more.   &    & and if i ever lose my eyes if my colours all run dry   & yes if i ever lose my eyes oh if i won't have to cry no more.   &    & [chorus]   &    & and if i ever lose my legs i won't moan and i won't beg   & yes if i ever lose my legs oh if i won't have to walk no more.   &    & and if i ever lose my mouth all my teeth north and south   & yes if i ever lose my mouth oh if i won't have to talk...   &    & did it take long to find me? i asked the faithful light.   & did it take long to find me? and are you gonna stay the night?   &    & [chorus]   & moonshadow moonshadow moonshadow moonshadow. &\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.iloc[8,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chorus \n",
      "\n",
      "oh i am being followed by a moonshadow moon shadow moonshadow \n",
      "\n",
      "leapin and hopping on a moonshadow moonshadow moonshadow \n",
      "\n",
      "\n",
      "\n",
      "and if i ever lose my hands lose my plough lose my land \n",
      "\n",
      "oh if i ever lose my hands oh if i will not have to work no more \n",
      "\n",
      "\n",
      "\n",
      "and if i ever lose my eyes if my colours all run dry \n",
      "\n",
      "yes if i ever lose my eyes oh if i will not have to cry no more \n",
      "\n",
      "\n",
      "\n",
      "chorus \n",
      "\n",
      "\n",
      "\n",
      "and if i ever lose my legs i will not moan and i will not beg \n",
      "\n",
      "yes if i ever lose my legs oh if i will not have to walk no more \n",
      "\n",
      "\n",
      "\n",
      "and if i ever lose my mouth all my teeth north and south \n",
      "\n",
      "yes if i ever lose my mouth oh if i will not have to talk \n",
      "\n",
      "\n",
      "\n",
      "did it take long to find me i asked the faithful light \n",
      "\n",
      "did it take long to find me and are you gon na stay the night \n",
      "\n",
      "\n",
      "\n",
      "chorus \n",
      "\n",
      "moonshadow moonshadow moonshadow moonshadow \n",
      "\n"
     ]
    }
   ],
   "source": [
    "string = df_train.iloc[8,2]\n",
    "tokenized_string = preprocess_lyrics(string)\n",
    "\n",
    "def pretty_lyrics(tokenized_string):\n",
    "    for token in tokenized_string:\n",
    "        if token == '&':\n",
    "            print('\\n')\n",
    "        else:\n",
    "            print(token, end=' ')\n",
    "\n",
    "pretty_lyrics(tokenized_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics = df_train['Lyrics'].apply(lambda s: preprocess_lyrics(s)[:-1] + ['$'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Create embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics = tokenizer.texts_to_sequences(lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_FILE = './GoogleNews-vectors-negative300.bin'\n",
    "\n",
    "if not os.path.isfile(EMBEDDING_FILE):\n",
    "    !wget -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\"\n",
    "    !gzip -f -d GoogleNews-vectors-negative300.bin.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "634 out of 7286 has no embedings from word2vec\n"
     ]
    }
   ],
   "source": [
    "from gensim import models\n",
    "\n",
    "embeddings_index = models.KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)\n",
    "embed_size = 300\n",
    "word_index = tokenizer.word_index\n",
    "max_features = len(word_index) + 1\n",
    "\n",
    "nb_words = len(word_index)\n",
    "embedding_matrix = (np.random.rand(nb_words+1, embed_size) - 0.5) / 5.0\n",
    "\n",
    "not_in_word2vec = 0\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    if word in embeddings_index:\n",
    "        embedding_vector = embeddings_index.get_vector(word)\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    else:\n",
    "        not_in_word2vec += 1\n",
    "        \n",
    "print(f'{not_in_word2vec} out of {len(word_index)} has no embedings from word2vec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying one word to whole song but one word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((191915, 1577), (191915, 7287))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x, train_y = [], []\n",
    "for lyric in lyrics:\n",
    "    for i in range(1, len(lyric)):\n",
    "        train_x.append(lyric[:i])\n",
    "        train_y.append(*lyric[i:i+1])\n",
    "        \n",
    "train_x = pad_sequences(train_x)\n",
    "train_y = to_categorical(train_y)\n",
    "train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying sliding window of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ast=np.lib.index_tricks.as_strided\n",
    "def generate_sliding_window(arr, window_size=5, window_stride=1, last_window=False):\n",
    "    last_window = 1 if last_window else 0\n",
    "    arr = np.ascontiguousarray(arr)\n",
    "    arr_len = arr.shape[0]\n",
    "    s, = arr.strides\n",
    "    windows_num = ((arr_len-window_size)//window_stride) + last_window\n",
    "    \n",
    "    return ast(arr, (windows_num, window_size), (s*window_stride, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((186380, 10), (186380, 7287))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x, train_y = [], []\n",
    "window_size = 10\n",
    "\n",
    "for lyric in lyrics:\n",
    "    train_x.append(generate_sliding_window(lyric, window_size))\n",
    "    train_y.append(lyric[window_size:])\n",
    "        \n",
    "train_x = np.concatenate(train_x)\n",
    "train_y = to_categorical(np.concatenate(train_y))\n",
    "train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = train_x.shape[1]\n",
    "\n",
    "def init_simple():\n",
    "    inp = Input(shape=(seq_len,))\n",
    "    \n",
    "    embd = Embedding(max_features, \n",
    "                      embed_size, \n",
    "                      weights=[embedding_matrix],\n",
    "                      input_length=seq_len,\n",
    "                      name='word_embd')(inp)\n",
    "    \n",
    "    lstm = LSTM(100, return_sequences=True)(embd)\n",
    "    lstm = LSTM(100)(lstm)\n",
    "\n",
    "    X = Dense(100, activation=\"relu\")(lstm)\n",
    "    X = Dropout(0.5)(X)\n",
    "    out = Dense(max_features, activation=\"softmax\", name = 'out')(X)\n",
    "\n",
    "    model = Model(inp, out)\n",
    "    \n",
    "#     model.get_layer('embd').trainable = False\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callbacks(model_name):\n",
    "    acc = 'val_loss'\n",
    "    acc_mode = 'min'\n",
    "#     acc = 'val_acc'\n",
    "#     acc_mode = 'max'\n",
    "    \n",
    "    checkpoint = ModelCheckpoint(\n",
    "                              fr'./models/{model_name}.h5', \n",
    "                              monitor=acc, \n",
    "#                               verbose=1, \n",
    "                              save_best_only=True, \n",
    "                              mode=acc_mode)\n",
    "    earlystop = EarlyStopping(monitor=acc, mode=acc_mode, verbose=0, patience=6)\n",
    "    reduceLR = ReduceLROnPlateau(monitor = 'val_loss', mode = 'min', patience = 5,\n",
    "                            factor = 0.5, min_lr = 1e-6, verbose = 0)\n",
    "\n",
    "    return [checkpoint, reduceLR] #earlystop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(model, train_x, train_y, use_saved=False, params_dict=None):\n",
    "    os.makedirs('./models', exist_ok=True)\n",
    "    \n",
    "    params = ''\n",
    "    if params_dict is not None:\n",
    "        params = '_'.join(f'{key}_{val}' for key,val in params_dict.items())\n",
    "    model_name = 'simple_model' + f'_{params}'\n",
    "    \n",
    "    \n",
    "    if use_saved:\n",
    "        history = joblib.load(fr'./models/{model_name}_history.sav')\n",
    "    else:\n",
    "        callbacks = get_callbacks(model_name)\n",
    "        history = model.fit(\n",
    "                            x=train_x,\n",
    "                            y=train_y,\n",
    "                            batch_size=params_dict['batch_size'],\n",
    "                            epochs=params_dict['epochs'],\n",
    "                            validation_split=params_dict['validation_split'],\n",
    "                            callbacks=callbacks,\n",
    "                            verbose=1\n",
    "                            )\n",
    "        \n",
    "        history = history.history\n",
    "        joblib.dump(history, fr'./models/{model_name}_history.sav')\n",
    "    \n",
    "    model = load_model(fr'./models/{model_name}.h5')\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 10)]              0         \n",
      "_________________________________________________________________\n",
      "word_embd (Embedding)        (None, 10, 300)           2186100   \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 10, 100)           160400    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "out (Dense)                  (None, 7287)              735987    \n",
      "=================================================================\n",
      "Total params: 3,172,987\n",
      "Trainable params: 3,172,987\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = init_simple()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4078/4078 [==============================] - 70s 17ms/step - loss: 4.0468 - val_loss: 5.6888\n",
      "Epoch 2/20\n",
      "4078/4078 [==============================] - 68s 17ms/step - loss: 3.8958 - val_loss: 5.8549\n",
      "Epoch 3/20\n",
      "4078/4078 [==============================] - 76s 19ms/step - loss: 3.7664 - val_loss: 6.0511\n",
      "Epoch 4/20\n",
      "4078/4078 [==============================] - 75s 18ms/step - loss: 3.6479 - val_loss: 6.2304\n",
      "Epoch 5/20\n",
      "4078/4078 [==============================] - 73s 18ms/step - loss: 3.5469 - val_loss: 6.3883\n",
      "Epoch 6/20\n",
      "4078/4078 [==============================] - 76s 19ms/step - loss: 3.4546 - val_loss: 6.7080\n",
      "Epoch 7/20\n",
      "4078/4078 [==============================] - 75s 18ms/step - loss: 3.2751 - val_loss: 7.0410\n",
      "Epoch 8/20\n",
      "4078/4078 [==============================] - 76s 19ms/step - loss: 3.1757 - val_loss: 7.4155\n",
      "Epoch 9/20\n",
      "4078/4078 [==============================] - 76s 19ms/step - loss: 3.1061 - val_loss: 7.6681\n",
      "Epoch 10/20\n",
      "4078/4078 [==============================] - 75s 19ms/step - loss: 3.0473 - val_loss: 8.0896\n",
      "Epoch 11/20\n",
      "4078/4078 [==============================] - 76s 19ms/step - loss: 2.9902 - val_loss: 8.2451\n",
      "Epoch 12/20\n",
      "4078/4078 [==============================] - 73s 18ms/step - loss: 2.8868 - val_loss: 8.7781\n",
      "Epoch 13/20\n",
      "4078/4078 [==============================] - 75s 18ms/step - loss: 2.8312 - val_loss: 8.9251\n",
      "Epoch 14/20\n",
      "4078/4078 [==============================] - 75s 18ms/step - loss: 2.7938 - val_loss: 9.1314\n",
      "Epoch 15/20\n",
      "4078/4078 [==============================] - 75s 18ms/step - loss: 2.7622 - val_loss: 9.4459\n",
      "Epoch 16/20\n",
      "4078/4078 [==============================] - 75s 18ms/step - loss: 2.7274 - val_loss: 9.5418\n",
      "Epoch 17/20\n",
      "4078/4078 [==============================] - 75s 18ms/step - loss: 2.6704 - val_loss: 9.8827\n",
      "Epoch 18/20\n",
      "4078/4078 [==============================] - 75s 19ms/step - loss: 2.6432 - val_loss: 10.0997\n",
      "Epoch 19/20\n",
      "4078/4078 [==============================] - 73s 18ms/step - loss: 2.6246 - val_loss: 10.4020\n",
      "Epoch 20/20\n",
      "4078/4078 [==============================] - 75s 18ms/step - loss: 2.6028 - val_loss: 10.3917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tensorflow.python.keras.engine.functional.Functional at 0x7fd82849dc90>,\n",
       " {'loss': [4.04681396484375,\n",
       "   3.8957934379577637,\n",
       "   3.766421318054199,\n",
       "   3.6478662490844727,\n",
       "   3.5469417572021484,\n",
       "   3.4546384811401367,\n",
       "   3.275069236755371,\n",
       "   3.1757025718688965,\n",
       "   3.1060564517974854,\n",
       "   3.047346591949463,\n",
       "   2.9901671409606934,\n",
       "   2.886751890182495,\n",
       "   2.831249475479126,\n",
       "   2.7937979698181152,\n",
       "   2.7621686458587646,\n",
       "   2.727421283721924,\n",
       "   2.670431613922119,\n",
       "   2.6432433128356934,\n",
       "   2.6246190071105957,\n",
       "   2.602755069732666],\n",
       "  'val_loss': [5.68879508972168,\n",
       "   5.854903221130371,\n",
       "   6.051053524017334,\n",
       "   6.230398654937744,\n",
       "   6.38828706741333,\n",
       "   6.7080078125,\n",
       "   7.040964126586914,\n",
       "   7.41554594039917,\n",
       "   7.668073654174805,\n",
       "   8.089550018310547,\n",
       "   8.245061874389648,\n",
       "   8.77805233001709,\n",
       "   8.925065994262695,\n",
       "   9.131375312805176,\n",
       "   9.445945739746094,\n",
       "   9.541833877563477,\n",
       "   9.882682800292969,\n",
       "   10.099723815917969,\n",
       "   10.402018547058105,\n",
       "   10.391733169555664],\n",
       "  'lr': [0.001,\n",
       "   0.001,\n",
       "   0.001,\n",
       "   0.001,\n",
       "   0.001,\n",
       "   0.001,\n",
       "   0.0005,\n",
       "   0.0005,\n",
       "   0.0005,\n",
       "   0.0005,\n",
       "   0.0005,\n",
       "   0.00025,\n",
       "   0.00025,\n",
       "   0.00025,\n",
       "   0.00025,\n",
       "   0.00025,\n",
       "   0.000125,\n",
       "   0.000125,\n",
       "   0.000125,\n",
       "   0.000125]})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_dict = {'batch_size': 32, 'epochs': 20, 'validation_split': 0.3}\n",
    "model, history= train_model(model, train_x, train_y, use_saved=True, params_dict=params_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "def generate_song(model, seed, window_size, stop_token, tokenizer, max_len):\n",
    "    stop_token = tokenizer.word_index[stop_token]\n",
    "    \n",
    "    \n",
    "    def get_next_word(seed):\n",
    "        probs = model.predict(seed)\n",
    "        chosen_idx = np.random.choice(range(0, max_features), p=probs[0])\n",
    "        chosen_word = tokenizer.sequences_to_texts([[chosen_idx]])[0]\n",
    "        \n",
    "        return chosen_idx, chosen_word\n",
    "    \n",
    "    \n",
    "    seed = preprocess_lyrics(seed)\n",
    "    song = seed.copy()\n",
    "    seed = \" \".join(seed)\n",
    "    seed = tokenizer.texts_to_sequences([seed])\n",
    "    seed = pad_sequences(seed, maxlen=window_size)\n",
    "\n",
    "    i = 0\n",
    "    \n",
    "    idx, word = get_next_word(seed)\n",
    "    \n",
    "    \n",
    "    while idx != stop_token and i < max_len:\n",
    "        song.append(word)\n",
    "        i+=1\n",
    "        seed = np.concatenate([seed[:,1:], [[idx]]], axis=1)\n",
    "        idx, word = get_next_word(seed)\n",
    "    \n",
    "    return song    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goodbye guy shani my love away \n",
      "\n",
      "oh i feel now about \n",
      "\n",
      "he the same \n",
      "\n",
      "did he know waiting back a working times \n",
      "\n",
      "everybody says you used to live \n",
      "\n",
      "want to show her it is not something \n",
      "\n",
      "then i thrill let him find rolling and knew his alone or our way \n",
      "\n",
      "will we love somebody looking because \n",
      "\n",
      "and i am sorry oh and love \n",
      "\n",
      "when i want to be with you \n",
      "\n",
      "i feel you try again like we feel \n",
      "\n",
      "was what we said then place two and all \n",
      "\n",
      "i am watching in the big pretty who wants you too \n",
      "\n",
      "on the toes in in mine \n",
      "\n",
      "in getting else of a fancy world \n",
      "\n",
      "i never find my genie in the man if i want you what could not make her a shubop \n",
      "\n",
      "will you make me so good back this love \n",
      "\n",
      "to time about to stop \n",
      "\n",
      "bring me a game down and see your scales and pullin \n",
      "\n",
      "you see a could call my twist eyes "
     ]
    }
   ],
   "source": [
    "\n",
    "song = generate_song(model, 'goodbye guy shani my love', 10, '$', tokenizer, 1000)\n",
    "pretty_lyrics(song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0, 306,  17, 105]], dtype=int32)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = preprocess_lyrics('close your eyes')\n",
    "seed = \" \".join(seed)\n",
    "seed = tokenizer.texts_to_sequences([seed])\n",
    "seed = pad_sequences(seed, maxlen=window_size)\n",
    "\n",
    "seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['0', '0', '0', '0', '0', '0', '306', '17', '105', 'cabbage']],\n",
       "      dtype='<U11')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([seed[:,1:], [[word]]], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "liav_notebook",
   "language": "python",
   "name": "liav_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
