{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/naorko/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/naorko/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    " \n",
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Concatenate\n",
    "from tensorflow.keras.layers import Dropout, Dense, Lambda\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Text preprocessing\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Plots\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Misc.\n",
    "import os\n",
    "import joblib\n",
    "import random\n",
    "import time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pretty_midi\n",
    "\n",
    "SEED = 42\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Singer', 'Song Name', 'Lyrics']\n",
    "\n",
    "df = pd.read_csv('datasets/lyrics_train_set.csv', names=cols)\n",
    "df_test = pd.read_csv('datasets/lyrics_test_set.csv', names=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove non rational lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Singer</th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>darude</td>\n",
       "      <td>sandstorm</td>\n",
       "      <td>[instrumental] &amp; du du dudududududuud &amp; dududu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Singer  Song Name                                             Lyrics\n",
       "315  darude  sandstorm  [instrumental] & du du dudududududuud & dududu..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_song = df.query(\"Singer == 'darude'\")\n",
    "bad_song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(axis=0, index=bad_song.index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add midi files' names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_midi_files(df):\n",
    "    midis = list(os.listdir(r'./datasets/midi_files'))\n",
    "    midis = {midi.lower()[:-4]: midi for midi in midis}    \n",
    "    \n",
    "    def combine_singer_song(singer, song):\n",
    "        key = f'{singer} - {song}'.replace(' ', '_').lower()\n",
    "        return midis[key] if key in midis else None\n",
    "    \n",
    "    df['Midi File'] = df.apply(lambda r: combine_singer_song(r['Singer'], r['Song Name']) ,axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_midi_files(df)\n",
    "df_test = add_midi_files(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check midi files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(619,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "midis = np.concatenate([df['Midi File'].values, df_test['Midi File'].values])\n",
    "midis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naorko/.conda/envs/tf-env/lib/python3.8/site-packages/pretty_midi/pretty_midi.py:97: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not decode key with 16 sharps and mode 1\n",
      "error readying midi file David_Bowie_-_Lazarus.mid\n",
      "Could not decode key with 1 flats and mode 255\n",
      "error readying midi file Beastie_Boys_-_Girls.mid\n",
      "data byte must be in range 0..127\n",
      "error readying midi file Billy_Joel_-_Movin'_Out.mid\n",
      "data byte must be in range 0..127\n",
      "error readying midi file Billy_Joel_-_Pressure.mid\n",
      "Could not decode key with 4 flats and mode 255\n",
      "error readying midi file Dan_Fogelberg_-_Leader_of_the_Band.mid\n",
      "\n",
      "error readying midi file Brian_McKnight_-_On_The_Down_Low.mid\n",
      "data byte must be in range 0..127\n",
      "error readying midi file Aaron_Neville_-_Tell_It_Like_It_Is.mid\n"
     ]
    }
   ],
   "source": [
    "corrupted = []\n",
    "for i, midi in enumerate(midis):\n",
    "    try:\n",
    "        midi = pretty_midi.PrettyMIDI(fr'./datasets/midi_files/{midi}')\n",
    "        midi.remove_invalid_notes()\n",
    "        del midi\n",
    "    except Exception as e:\n",
    "        print(\"%s\\nerror readying midi file %s\" % (e, midi))\n",
    "        corrupted.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Singer</th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Midi File</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>david bowie</td>\n",
       "      <td>lazarus</td>\n",
       "      <td>look up here i'm in heaven &amp; i've got scars th...</td>\n",
       "      <td>David_Bowie_-_Lazarus.mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>beastie boys</td>\n",
       "      <td>girls</td>\n",
       "      <td>girls all i really want is girls &amp; and in the ...</td>\n",
       "      <td>Beastie_Boys_-_Girls.mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>billy joel</td>\n",
       "      <td>movin' out</td>\n",
       "      <td>anthony works in the grocery store   &amp; savin h...</td>\n",
       "      <td>Billy_Joel_-_Movin'_Out.mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>billy joel</td>\n",
       "      <td>pressure</td>\n",
       "      <td>you have to learn to pace yourself &amp; pressure ...</td>\n",
       "      <td>Billy_Joel_-_Pressure.mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>dan fogelberg</td>\n",
       "      <td>leader of the band</td>\n",
       "      <td>an only child alone and wild a cabinet maker's...</td>\n",
       "      <td>Dan_Fogelberg_-_Leader_of_the_Band.mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>brian mcknight</td>\n",
       "      <td>on the down low</td>\n",
       "      <td>maxine was 5'9'' &amp; had a man and she didn't mi...</td>\n",
       "      <td>Brian_McKnight_-_On_The_Down_Low.mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>aaron neville</td>\n",
       "      <td>tell it like it is</td>\n",
       "      <td>if you want something to play with &amp; go and fi...</td>\n",
       "      <td>Aaron_Neville_-_Tell_It_Like_It_Is.mid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Singer           Song Name  \\\n",
       "91      david bowie             lazarus   \n",
       "115    beastie boys               girls   \n",
       "136      billy joel          movin' out   \n",
       "143      billy joel            pressure   \n",
       "189   dan fogelberg  leader of the band   \n",
       "513  brian mcknight     on the down low   \n",
       "575   aaron neville  tell it like it is   \n",
       "\n",
       "                                                Lyrics  \\\n",
       "91   look up here i'm in heaven & i've got scars th...   \n",
       "115  girls all i really want is girls & and in the ...   \n",
       "136  anthony works in the grocery store   & savin h...   \n",
       "143  you have to learn to pace yourself & pressure ...   \n",
       "189  an only child alone and wild a cabinet maker's...   \n",
       "513  maxine was 5'9'' & had a man and she didn't mi...   \n",
       "575  if you want something to play with & go and fi...   \n",
       "\n",
       "                                  Midi File  \n",
       "91                David_Bowie_-_Lazarus.mid  \n",
       "115                Beastie_Boys_-_Girls.mid  \n",
       "136             Billy_Joel_-_Movin'_Out.mid  \n",
       "143               Billy_Joel_-_Pressure.mid  \n",
       "189  Dan_Fogelberg_-_Leader_of_the_Band.mid  \n",
       "513    Brian_McKnight_-_On_The_Down_Low.mid  \n",
       "575  Aaron_Neville_-_Tell_It_Like_It_Is.mid  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_songs = df.iloc[corrupted]\n",
    "bad_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(axis=0, index=bad_songs.index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = np.random.rand(len(df)) < 0.8\n",
    "\n",
    "df_train = df[msk]\n",
    "df_val = df[~msk]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lyrics preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    phrase = re.sub(r\"in\\'\", \"ing\", phrase)\n",
    "    phrase = re.sub(r\"y\\'all\", \"you all\", phrase)\n",
    "    phrase = re.sub(r\"hiya\", \"hi you\", phrase)\n",
    "    \n",
    "    # punctions\n",
    "    regex = re.compile('[^a-zA-Z& ]')\n",
    "    phrase = regex.sub('', phrase)\n",
    "    \n",
    "    return phrase\n",
    "\n",
    "def preprocess_lyrics(data):\n",
    "    data = decontracted(data)\n",
    "    tokens = word_tokenize(data)\n",
    "    data_arr = []\n",
    "    \n",
    "    for t in tokens:\n",
    "        # Use only words, character combinations and numbers \n",
    "#         if not t.isalpha(): \n",
    "#             continue\n",
    "            \n",
    "        # Lower case word\n",
    "        t = t.lower()\n",
    "        \n",
    "#         # Remove stop words\n",
    "#         if t in sw: \n",
    "#             continue\n",
    "        \n",
    "        data_arr.append(t)\n",
    "    \n",
    "    \n",
    "    return data_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"you know i need your love & you've got that hold over me & long as i've got your love & you know that i'll never leave & when i wanted you to share my life & i had no doubt in my mind & and it's been you woman & right down the line & i know how much i lean on you & only you can see & the changes that i've been through & have left a mark on me & you've been as constant as a northern star & the brightest light that shines & it's been you woman right down the line & i just want to say this is my way & of tellin' you everything & i could never say before & yeah this is my way of tellin' you & that every day i'm lovin' you so much more & 'cause you believed in me through my darkest night & put somethin' better inside of me & you brought me into the light & threw away all those crazy dreams & i put them all behind & and it was you woman & right down the line & i just want to say this is my way of tellin' you everything & i could never say before & yeah this is my way of tellin' you & everything i could never say before & yeah this is my way of tellin' you & that every day i'm lovin' you so much more &\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.iloc[1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you know i need your love \n",
      "\n",
      "you have got that hold over me \n",
      "\n",
      "long as i have got your love \n",
      "\n",
      "you know that i will never leave \n",
      "\n",
      "when i wanted you to share my life \n",
      "\n",
      "i had no doubt in my mind \n",
      "\n",
      "and it is been you woman \n",
      "\n",
      "right down the line \n",
      "\n",
      "i know how much i lean on you \n",
      "\n",
      "only you can see \n",
      "\n",
      "the changes that i have been through \n",
      "\n",
      "have left a mark on me \n",
      "\n",
      "you have been as constant as a northern star \n",
      "\n",
      "the brightest light that shines \n",
      "\n",
      "it is been you woman right down the line \n",
      "\n",
      "i just want to say this is my way \n",
      "\n",
      "of telling you everything \n",
      "\n",
      "i could never say before \n",
      "\n",
      "yeah this is my way of telling you \n",
      "\n",
      "that every day i am loving you so much more \n",
      "\n",
      "cause you believed in me through my darkest night \n",
      "\n",
      "put something better inside of me \n",
      "\n",
      "you brought me into the light \n",
      "\n",
      "threw away all those crazy dreams \n",
      "\n",
      "i put them all behind \n",
      "\n",
      "and it was you woman \n",
      "\n",
      "right down the line \n",
      "\n",
      "i just want to say this is my way of telling you everything \n",
      "\n",
      "i could never say before \n",
      "\n",
      "yeah this is my way of telling you \n",
      "\n",
      "everything i could never say before \n",
      "\n",
      "yeah this is my way of telling you \n",
      "\n",
      "that every day i am loving you so much more \n",
      "\n"
     ]
    }
   ],
   "source": [
    "string = df_train.iloc[1,2]\n",
    "tokenized_string = preprocess_lyrics(string)\n",
    "\n",
    "def pretty_lyrics(tokenized_string):\n",
    "    for token in tokenized_string:\n",
    "        if token == '&':\n",
    "            print('\\n')\n",
    "        else:\n",
    "            print(token, end=' ')\n",
    "\n",
    "pretty_lyrics(tokenized_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_token = '$'\n",
    "lyrics_train = df_train['Lyrics'].apply(lambda s: preprocess_lyrics(s)[:-1] + [stop_token])\n",
    "lyrics_val = df_val['Lyrics'].apply(lambda s: preprocess_lyrics(s)[:-1] + [stop_token])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(lyrics_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_train = tokenizer.texts_to_sequences(lyrics_train)\n",
    "lyrics_val = tokenizer.texts_to_sequences(lyrics_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_FILE = './GoogleNews-vectors-negative300.bin'\n",
    "\n",
    "if not os.path.isfile(EMBEDDING_FILE):\n",
    "    !wget -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\"\n",
    "    !gzip -f -d GoogleNews-vectors-negative300.bin.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505 out of 6238 has no embedings from word2vec\n"
     ]
    }
   ],
   "source": [
    "from gensim import models\n",
    "\n",
    "embeddings_index = models.KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)\n",
    "embed_size = 300\n",
    "word_index = tokenizer.word_index\n",
    "max_features = len(word_index) + 1\n",
    "\n",
    "nb_words = len(word_index)\n",
    "embedding_matrix = (np.random.rand(nb_words+1, embed_size) - 0.5) / 5.0\n",
    "\n",
    "not_in_word2vec = 0\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    if word in embeddings_index:\n",
    "        embedding_vector = embeddings_index.get_vector(word)\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    else:\n",
    "        not_in_word2vec += 1\n",
    "        \n",
    "print(f'{not_in_word2vec} out of {len(word_index)} has no embedings from word2vec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying one word to whole song but one word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x, train_y = [], []\n",
    "\n",
    "# for lyric in lyrics:\n",
    "#     for i in range(1, len(lyric)):\n",
    "#         train_x.append(lyric[:i])\n",
    "#         train_y.append(*lyric[i:i+1])\n",
    "        \n",
    "# train_x = pad_sequences(train_x)\n",
    "# train_y = to_categorical(train_y)\n",
    "# train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying sliding window of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ast=np.lib.index_tricks.as_strided\n",
    "def generate_sliding_window(arr, window_size=5, window_stride=1, last_window=False):\n",
    "    last_window = 1 if last_window else 0\n",
    "    arr = np.ascontiguousarray(arr)\n",
    "    arr_len = arr.shape[0]\n",
    "    s, = arr.strides\n",
    "    windows_num = ((arr_len-window_size)//window_stride) + last_window\n",
    "    \n",
    "    return ast(arr, (windows_num, window_size), (s*window_stride, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_lyrics(lyrics, window_size=10):\n",
    "    X, y = [], []\n",
    "    for lyric in lyrics:\n",
    "        X.append(generate_sliding_window(lyric, window_size))\n",
    "        y.append(to_categorical(lyric[window_size:], num_classes=max_features))\n",
    "        \n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 10\n",
    "lyrics_train = split_lyrics(lyrics_train, window_size)\n",
    "lyrics_val = split_lyrics(lyrics_val, window_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Melody preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ast=np.lib.index_tricks.as_strided\n",
    "def generate_sliding_window_2d(arr, window_size=5, window_stride=1, last_window=False):\n",
    "    last_window = 1 if last_window else 0\n",
    "    arr = np.ascontiguousarray(arr)\n",
    "    l0, l1 = arr.shape\n",
    "    s0, s1 = arr.strides\n",
    "    windows_num = ((l0-window_size)//window_stride) + last_window\n",
    "    \n",
    "    return ast(arr, (windows_num, window_size, l1), (s0*window_stride, s0, s1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_melody_file_by_time(midi_name, fs=5, max_piano_val=100, fpw=4, window_size=10):\n",
    "    pm = pretty_midi.PrettyMIDI(fr'./datasets/midi_files/{midi_name}')\n",
    "    pm.remove_invalid_notes()\n",
    "    \n",
    "    # Sum all notes from all instruments\n",
    "    piano_all = pm.get_piano_roll(fs=fs)\n",
    "    piano_shape = piano_all.shape\n",
    "\n",
    "    # Normalize by the number of played instruments in the same time and note\n",
    "    counter = np.zeros(piano_shape)\n",
    "    for inst in pm.instruments:\n",
    "        curr_piano = inst.get_piano_roll(fs=fs)\n",
    "\n",
    "        counter[:, :curr_piano.shape[1]] += (curr_piano > 0).astype(int)\n",
    "\n",
    "    counter[counter == 0] = 1\n",
    "    piano_all /= counter\n",
    "    \n",
    "    # Normalize by the maximum value of a note\n",
    "    piano_all = piano_all / max_piano_val\n",
    "    \n",
    "    # Normalize by the number of played notes in the same time\n",
    "    count_notes = (piano_all > 0).sum(axis=0)\n",
    "    count_notes[count_notes == 0] = 1\n",
    "    melody = piano_all.sum(axis=0) / count_notes\n",
    "    del piano_all\n",
    "    \n",
    "    # 3 frames of 5fps equal to 0.6s ~ about one word\n",
    "    melody_per_word = generate_sliding_window(melody[(melody > 0).argmax():], window_size=fpw, window_stride=(fpw*2)//5, last_window=True)\n",
    "    melody_windows = generate_sliding_window_2d(melody_per_word, window_size=window_size, last_window=True)\n",
    "    \n",
    "    return melody_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7e529a1c2d64a998508764acf019d1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=612), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naorko/.conda/envs/tf-env/lib/python3.8/site-packages/pretty_midi/pretty_midi.py:97: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The maximum note value is 762.0\n",
      "The minimum song length is 297\n",
      "The maximum song length is 3006\n"
     ]
    }
   ],
   "source": [
    "midis = np.concatenate([df['Midi File'].values, df_test['Midi File'].values])\n",
    "fs = 5\n",
    "\n",
    "max_note_val = -1\n",
    "min_frames = 9999\n",
    "max_frames = -1\n",
    "for midi in tqdm(midis):\n",
    "    pm = pretty_midi.PrettyMIDI(fr'./datasets/midi_files/{midi}')\n",
    "    pm.remove_invalid_notes()\n",
    "    \n",
    "    piano_roll = pm.get_piano_roll(fs=fs)\n",
    "    if piano_roll.shape[1]:\n",
    "        curr_len = piano_roll.shape[1]\n",
    "        min_frames = min(min_frames, curr_len)\n",
    "        max_frames = max(max_frames, curr_len)\n",
    "        \n",
    "    for inst in pm.instruments:\n",
    "        piano_roll = inst.get_piano_roll(fs=fs)\n",
    "        if piano_roll.shape[1]:\n",
    "            curr_max_note = piano_roll.max()\n",
    "            max_note_val = max(max_note_val, curr_max_note)\n",
    "        \n",
    "    del pm\n",
    "\n",
    "print(f'The maximum note value is {max_note_val}')\n",
    "print(f'The minimum song length is {min_frames}')\n",
    "print(f'The maximum song length is {max_frames}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naorko/.conda/envs/tf-env/lib/python3.8/site-packages/pretty_midi/pretty_midi.py:97: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "melody_train = df_train['Midi File'].apply(preprocess_melody_file_by_time, fs=100, max_piano_val=762, fpw=100, window_size=10)\n",
    "melody_val = df_val['Midi File'].apply(preprocess_melody_file_by_time, fs=100, max_piano_val=762, fpw=100, window_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_x_y(lyrics, melody):\n",
    "    for i in range(len(lyrics[0])):\n",
    "        mel_len = melody.iloc[i].shape[0]\n",
    "        lyr_len = lyrics[0][i].shape[0]\n",
    "        \n",
    "        if mel_len >= lyr_len:\n",
    "            melody.iloc[i] = melody.iloc[i][:lyr_len, :, :]\n",
    "        else:\n",
    "            lyrics[0][i] = lyrics[0][i][:mel_len, :]\n",
    "            lyrics[1][i] = lyrics[1][i][:mel_len, :]\n",
    "            \n",
    "    lyrics_X = np.concatenate(lyrics[0])\n",
    "    lyrics_y = np.concatenate(lyrics[1])\n",
    "    del lyrics\n",
    "    melody = np.concatenate(melody.values)\n",
    "            \n",
    "    return (melody, lyrics_X), lyrics_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = prepare_x_y(lyrics_train, melody_train)\n",
    "val_data = prepare_x_y(lyrics_val, melody_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Lyrics Generator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_slided_melody(window_size, melody_features):\n",
    "    input_melody = Input(shape=(window_size, melody_features), name='melody')\n",
    "    input_lyrics = Input(shape=(window_size,), name='lyrics')\n",
    "    \n",
    "    embd_lyrics = Embedding(max_features, \n",
    "                      embed_size, \n",
    "                      weights=[embedding_matrix],\n",
    "                      input_length=window_size,\n",
    "                      name='word_embd')(input_lyrics)\n",
    "    \n",
    "    merged = Concatenate(axis=2, name='merge')([embd_lyrics, input_melody])\n",
    "    \n",
    "    lstm = LSTM(100, return_sequences=True)(merged)\n",
    "    lstm = LSTM(100)(lstm)\n",
    "\n",
    "    X = Dense(100, activation=\"relu\")(lstm)\n",
    "    X = Dropout(0.5)(X)\n",
    "    out = Dense(max_features, activation=\"softmax\", name = 'out')(X)\n",
    "\n",
    "    model = Model([input_melody, input_lyrics], out)\n",
    "    \n",
    "#     model.get_layer('embd').trainable = False\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "lyrics (InputLayer)             [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "word_embd (Embedding)           (None, 10, 300)      1871700     lyrics[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "melody (InputLayer)             [(None, 10, 100)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge (Concatenate)             (None, 10, 400)      0           word_embd[0][0]                  \n",
      "                                                                 melody[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 10, 100)      200400      merge[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 100)          80400       lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 100)          10100       lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 100)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "out (Dense)                     (None, 6239)         630139      dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,792,739\n",
      "Trainable params: 2,792,739\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = init_slided_melody(10,100)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_simple(seq_len):\n",
    "    inp = Input(shape=(seq_len,))\n",
    "    \n",
    "    embd = Embedding(max_features, \n",
    "                      embed_size, \n",
    "                      weights=[embedding_matrix],\n",
    "                      input_length=seq_len,\n",
    "                      name='word_embd')(inp)\n",
    "    \n",
    "    lstm = LSTM(100, return_sequences=True)(embd)\n",
    "    lstm = LSTM(100)(lstm)\n",
    "\n",
    "    X = Dense(100, activation=\"relu\")(lstm)\n",
    "    X = Dropout(0.5)(X)\n",
    "    out = Dense(max_features, activation=\"softmax\", name = 'out')(X)\n",
    "\n",
    "    model = Model(inp, out)\n",
    "    \n",
    "#     model.get_layer('embd').trainable = False\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callbacks(model_name):\n",
    "    acc = 'val_loss'\n",
    "    acc_mode = 'min'\n",
    "    \n",
    "    checkpoint = ModelCheckpoint(\n",
    "                              fr'./models/{model_name}.h5', \n",
    "                              monitor=acc, \n",
    "#                               verbose=1, \n",
    "                              save_best_only=True, \n",
    "                              mode=acc_mode)\n",
    "    earlystop = EarlyStopping(monitor=acc, mode=acc_mode, verbose=1, patience=6)\n",
    "    reduceLR = ReduceLROnPlateau(monitor = 'val_loss', mode = 'min', patience = 5,\n",
    "                            factor = 0.5, min_lr = 1e-6, verbose = 1)\n",
    "\n",
    "    return [checkpoint, reduceLR] #earlystop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_gen, train_data, val_data, use_saved=False, params_dict=None):\n",
    "    os.makedirs('./models', exist_ok=True)\n",
    "    params = ''\n",
    "    if params_dict is not None:\n",
    "        params = '_'.join(f'{key}_{val}' for key,val in params_dict.items())\n",
    "    model_name = model_gen.__name__[5:] + f'_{params}'\n",
    "        \n",
    "    if use_saved:\n",
    "        history = joblib.load(fr'./models/{model_name}_history.sav')\n",
    "    else:\n",
    "        callbacks = get_callbacks(model_name)\n",
    "        \n",
    "        train_x, train_y = train_data\n",
    "        \n",
    "        model = model_gen(*train_x[0].shape[1:]) # melody size\n",
    "        history = model.fit(\n",
    "                            x=train_x,\n",
    "                            y=train_y,\n",
    "                            batch_size=params_dict['batch_size'],\n",
    "                            epochs=params_dict['epochs'],\n",
    "                            validation_data=val_data,\n",
    "                            callbacks=callbacks,\n",
    "                            verbose=1\n",
    "                            )\n",
    "        \n",
    "        history = history.history\n",
    "        joblib.dump(history, fr'./models/{model_name}_history.sav')\n",
    "    \n",
    "    model = load_model(fr'./models/{model_name}.h5')\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        [(None, 1204)]            0         \n",
      "_________________________________________________________________\n",
      "word_embd (Embedding)        (None, 1204, 300)         1913400   \n",
      "_________________________________________________________________\n",
      "lstm_17 (LSTM)               (None, 1204, 100)         160400    \n",
      "_________________________________________________________________\n",
      "lstm_18 (LSTM)               (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "out (Dense)                  (None, 6378)              644178    \n",
      "=================================================================\n",
      "Total params: 2,808,478\n",
      "Trainable params: 2,808,478\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = init_simple(train_x.shape[1])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4619/4619 [==============================] - 86s 17ms/step - loss: 5.7913 - val_loss: 5.0301\n",
      "Epoch 2/20\n",
      "4619/4619 [==============================] - 70s 15ms/step - loss: 4.9867 - val_loss: 4.8607\n",
      "Epoch 3/20\n",
      "4619/4619 [==============================] - 69s 15ms/step - loss: 4.6565 - val_loss: 4.8774\n",
      "Epoch 4/20\n",
      "4619/4619 [==============================] - 76s 16ms/step - loss: 4.4195 - val_loss: 4.9408\n",
      "Epoch 5/20\n",
      "4619/4619 [==============================] - 76s 16ms/step - loss: 4.2456 - val_loss: 5.0937\n",
      "Epoch 6/20\n",
      "4619/4619 [==============================] - 77s 17ms/step - loss: 4.0573 - val_loss: 5.2618\n",
      "Epoch 7/20\n",
      "4619/4619 [==============================] - 76s 17ms/step - loss: 3.9183 - val_loss: 5.4201\n",
      "Epoch 8/20\n",
      "4619/4619 [==============================] - 76s 16ms/step - loss: 3.7498 - val_loss: 5.7651\n",
      "Epoch 9/20\n",
      "4619/4619 [==============================] - 75s 16ms/step - loss: 3.6126 - val_loss: 5.9113\n",
      "Epoch 10/20\n",
      "4619/4619 [==============================] - 77s 17ms/step - loss: 3.5423 - val_loss: 6.2786\n",
      "Epoch 11/20\n",
      "4619/4619 [==============================] - 77s 17ms/step - loss: 3.4657 - val_loss: 6.6475\n",
      "Epoch 12/20\n",
      "4619/4619 [==============================] - 76s 16ms/step - loss: 3.3858 - val_loss: 6.7223\n",
      "Epoch 13/20\n",
      "4619/4619 [==============================] - 76s 17ms/step - loss: 3.2913 - val_loss: 7.0218\n",
      "Epoch 14/20\n",
      "4619/4619 [==============================] - 76s 16ms/step - loss: 3.2235 - val_loss: 7.2949\n",
      "Epoch 15/20\n",
      "4619/4619 [==============================] - 76s 16ms/step - loss: 3.1806 - val_loss: 7.3991\n",
      "Epoch 16/20\n",
      "4619/4619 [==============================] - 75s 16ms/step - loss: 3.1418 - val_loss: 7.8695\n",
      "Epoch 17/20\n",
      "4619/4619 [==============================] - 76s 16ms/step - loss: 3.1013 - val_loss: 7.8988\n",
      "Epoch 18/20\n",
      "4619/4619 [==============================] - 76s 17ms/step - loss: 3.0494 - val_loss: 8.1687\n",
      "Epoch 19/20\n",
      "4619/4619 [==============================] - 76s 16ms/step - loss: 3.0154 - val_loss: 8.3088\n",
      "Epoch 20/20\n",
      "4619/4619 [==============================] - 76s 16ms/step - loss: 2.9887 - val_loss: 8.4389\n"
     ]
    }
   ],
   "source": [
    "params_dict = {'batch_size': 32, 'epochs': 20}\n",
    "model, history= train_model(init_simple, train_data, val_data, use_saved=False, params_dict=params_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4260/4260 [==============================] - 44s 10ms/step - loss: 5.5234 - val_loss: 5.0505 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "4260/4260 [==============================] - 39s 9ms/step - loss: 4.9823 - val_loss: 4.8540 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "4260/4260 [==============================] - 43s 10ms/step - loss: 4.6895 - val_loss: 4.8580 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "4260/4260 [==============================] - 46s 11ms/step - loss: 4.4685 - val_loss: 4.9278 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "4260/4260 [==============================] - 47s 11ms/step - loss: 4.2841 - val_loss: 5.0157 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "4260/4260 [==============================] - 48s 11ms/step - loss: 4.1239 - val_loss: 5.1590 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "4258/4260 [============================>.] - ETA: 0s - loss: 3.9812\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4260/4260 [==============================] - 41s 10ms/step - loss: 3.9813 - val_loss: 5.2791 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "4260/4260 [==============================] - 45s 11ms/step - loss: 3.7832 - val_loss: 5.5701 - lr: 5.0000e-04\n",
      "Epoch 9/20\n",
      "4260/4260 [==============================] - 38s 9ms/step - loss: 3.6751 - val_loss: 5.7743 - lr: 5.0000e-04\n",
      "Epoch 10/20\n",
      "4260/4260 [==============================] - 43s 10ms/step - loss: 3.5903 - val_loss: 5.9208 - lr: 5.0000e-04\n",
      "Epoch 11/20\n",
      "4260/4260 [==============================] - 46s 11ms/step - loss: 3.5104 - val_loss: 6.2043 - lr: 5.0000e-04\n",
      "Epoch 12/20\n",
      "4260/4260 [==============================] - ETA: 0s - loss: 3.4369\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4260/4260 [==============================] - 46s 11ms/step - loss: 3.4369 - val_loss: 6.3856 - lr: 5.0000e-04\n",
      "Epoch 13/20\n",
      "4260/4260 [==============================] - 46s 11ms/step - loss: 3.3209 - val_loss: 6.6525 - lr: 2.5000e-04\n",
      "Epoch 14/20\n",
      "4260/4260 [==============================] - 47s 11ms/step - loss: 3.2640 - val_loss: 6.8138 - lr: 2.5000e-04\n",
      "Epoch 15/20\n",
      "4260/4260 [==============================] - 38s 9ms/step - loss: 3.2212 - val_loss: 6.9686 - lr: 2.5000e-04\n",
      "Epoch 16/20\n",
      "4260/4260 [==============================] - 43s 10ms/step - loss: 3.1809 - val_loss: 7.1376 - lr: 2.5000e-04\n",
      "Epoch 17/20\n",
      "4256/4260 [============================>.] - ETA: 0s - loss: 3.1408\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "4260/4260 [==============================] - 48s 11ms/step - loss: 3.1406 - val_loss: 7.4627 - lr: 2.5000e-04\n",
      "Epoch 18/20\n",
      "4260/4260 [==============================] - 38s 9ms/step - loss: 3.0781 - val_loss: 7.5962 - lr: 1.2500e-04\n",
      "Epoch 19/20\n",
      "4260/4260 [==============================] - 42s 10ms/step - loss: 3.0475 - val_loss: 7.6885 - lr: 1.2500e-04\n",
      "Epoch 20/20\n",
      "4260/4260 [==============================] - 46s 11ms/step - loss: 3.0287 - val_loss: 7.9438 - lr: 1.2500e-04\n"
     ]
    }
   ],
   "source": [
    "params_dict = {'batch_size': 32, 'epochs': 20}\n",
    "model, history= train_model(init_slided_melody, train_data, val_data, use_saved=False, params_dict=params_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Lyrics by Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_song(model, seed, window_size, stop_token, tokenizer, max_len):\n",
    "    stop_token = tokenizer.word_index[stop_token]\n",
    "    \n",
    "    def get_next_word(seed):\n",
    "        probs = model(seed, training=False)\n",
    "        chosen_idx = np.random.choice(range(0, max_features), p=probs[0])\n",
    "        chosen_word = tokenizer.sequences_to_texts([[chosen_idx]])[0]\n",
    "        \n",
    "        return chosen_idx, chosen_word\n",
    "    \n",
    "    \n",
    "    seed = preprocess_lyrics(seed)\n",
    "    song = seed.copy()\n",
    "    seed = ' '.join(seed)\n",
    "    seed = tokenizer.texts_to_sequences([seed])\n",
    "    seed = pad_sequences(seed, maxlen=window_size)\n",
    "\n",
    "    i = 0\n",
    "    idx, word = get_next_word(seed)\n",
    "    while word != stop_token and i < max_len:\n",
    "        song.append(word)\n",
    "        i+=1\n",
    "        seed = np.concatenate([seed[:,1:], [[idx]]], axis=1)\n",
    "        idx, word = get_next_word(seed)\n",
    "    \n",
    "    return song    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_max_length = 2000\n",
    "seed = 'Smack that all on the floor'\n",
    "song = generate_song(model, seed, window_size, stop_token, tokenizer, song_max_length)\n",
    "pretty_lyrics(song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Singer</th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Midi File</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the bangles</td>\n",
       "      <td>eternal flame</td>\n",
       "      <td>close your eyes give me your hand darling &amp; do...</td>\n",
       "      <td>The_Bangles_-_Eternal_Flame.mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>billy joel</td>\n",
       "      <td>honesty</td>\n",
       "      <td>if you search for tenderness &amp; it isn't hard t...</td>\n",
       "      <td>Billy_Joel_-_Honesty.mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cardigans</td>\n",
       "      <td>lovefool</td>\n",
       "      <td>dear i fear we're facing a problem &amp; you love ...</td>\n",
       "      <td>Cardigans_-_Lovefool.mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aqua</td>\n",
       "      <td>barbie girl</td>\n",
       "      <td>hiya barbie &amp; hi ken! &amp; do you want to go for ...</td>\n",
       "      <td>Aqua_-_Barbie_Girl.mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blink 182</td>\n",
       "      <td>all the small things</td>\n",
       "      <td>all the small things &amp; true care truth brings ...</td>\n",
       "      <td>Blink_182_-_All_the_Small_Things.mid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Singer             Song Name  \\\n",
       "0  the bangles         eternal flame   \n",
       "1   billy joel               honesty   \n",
       "2    cardigans              lovefool   \n",
       "3         aqua           barbie girl   \n",
       "4    blink 182  all the small things   \n",
       "\n",
       "                                              Lyrics  \\\n",
       "0  close your eyes give me your hand darling & do...   \n",
       "1  if you search for tenderness & it isn't hard t...   \n",
       "2  dear i fear we're facing a problem & you love ...   \n",
       "3  hiya barbie & hi ken! & do you want to go for ...   \n",
       "4  all the small things & true care truth brings ...   \n",
       "\n",
       "                              Midi File  \n",
       "0       The_Bangles_-_Eternal_Flame.mid  \n",
       "1              Billy_Joel_-_Honesty.mid  \n",
       "2              Cardigans_-_Lovefool.mid  \n",
       "3                Aqua_-_Barbie_Girl.mid  \n",
       "4  Blink_182_-_All_the_Small_Things.mid  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_song_with_melody(model, lyrics_seed, midi_name, window_size, tokenizer, max_len, fpw=100, stop_token='$'):\n",
    "    stop_token_idx = tokenizer.word_index[stop_token]\n",
    "    melody = preprocess_melody_file_by_time(midi_name, fs=100, max_piano_val=762, fpw=fpw, window_size=window_size)\n",
    "    \n",
    "    def get_next_word(lyrics_seed, melody_seed):\n",
    "        if melody_seed is None:\n",
    "            return stop_token_idx, stop_token\n",
    "        try:\n",
    "            probs = model((melody_seed, lyrics_seed), training=False)\n",
    "            probs = probs[0] / np.sum(probs[0])\n",
    "            chosen_idx = np.random.choice(range(0, max_features), p=probs)\n",
    "            chosen_word = tokenizer.sequences_to_texts([[chosen_idx]])[0]\n",
    "            \n",
    "        except:\n",
    "            return stop_token_idx, stop_token\n",
    "        \n",
    "        return chosen_idx, chosen_word\n",
    "    \n",
    "    def get_melody_seed(word_cnt):\n",
    "        if word_cnt - window_size >= melody.shape[0]:\n",
    "            return None\n",
    "        \n",
    "        if word_cnt < window_size:\n",
    "            melody_seed = np.concatenate([np.zeros((window_size-word_cnt,fpw)),melody[0][:word_cnt,:fpw]])\n",
    "        else:\n",
    "            window_idx = word_cnt-window_size\n",
    "            \n",
    "            if window_idx >= melody.shape[0]: # Melody has ended\n",
    "                return None\n",
    "            \n",
    "            melody_seed = melody[window_idx]\n",
    "        \n",
    "        return np.expand_dims(melody_seed, axis=0)\n",
    "    \n",
    "    \n",
    "    lyrics_seed = preprocess_lyrics(lyrics_seed)\n",
    "    song = lyrics_seed.copy()\n",
    "    lyrics_seed = ' '.join(lyrics_seed)\n",
    "    lyrics_seed = tokenizer.texts_to_sequences([lyrics_seed])\n",
    "    word_cnt = len(lyrics_seed[0])\n",
    "    lyrics_seed = pad_sequences(lyrics_seed, maxlen=window_size)\n",
    "\n",
    "    melody_seed = get_melody_seed(word_cnt)\n",
    "    idx, word = get_next_word(lyrics_seed, melody_seed)\n",
    "    while idx != stop_token_idx and word_cnt < max_len:\n",
    "        song.append(word)\n",
    "        word_cnt+=1\n",
    "        lyrics_seed = np.concatenate([lyrics_seed[:,1:], [[idx]]], axis=1)\n",
    "        melody_seed = get_melody_seed(word_cnt)\n",
    "        idx, word = get_next_word(lyrics_seed)\n",
    "    \n",
    "    return song    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi you "
     ]
    }
   ],
   "source": [
    "window_size = 10\n",
    "song_max_length = 2000\n",
    "lyrics_seed = 'hiya'\n",
    "midi_name = 'Aqua_-_Barbie_Girl.mid'\n",
    "song = generate_song_with_melody(model, lyrics_seed, midi_name, window_size, tokenizer, window_size, fpw=100)\n",
    "\n",
    "pretty_lyrics(song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-env)",
   "language": "python",
   "name": "tf-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
