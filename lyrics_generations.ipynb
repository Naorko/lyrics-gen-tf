{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    " \n",
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Concatenate\n",
    "from tensorflow.keras.layers import Dropout, Dense, Lambda\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Text preprocessing\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Plots\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Misc.\n",
    "import os\n",
    "import joblib\n",
    "import random\n",
    "import time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pretty_midi\n",
    "\n",
    "SEED = 42\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Singer', 'Song Name', 'Lyrics']\n",
    "\n",
    "df = pd.read_csv('datasets/lyrics_train_set.csv', names=cols)\n",
    "df_test = pd.read_csv('datasets/lyrics_test_set.csv', names=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove non rational lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Singer</th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>darude</td>\n",
       "      <td>sandstorm</td>\n",
       "      <td>[instrumental] &amp; du du dudududududuud &amp; dududu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Singer  Song Name                                             Lyrics\n",
       "315  darude  sandstorm  [instrumental] & du du dudududududuud & dududu..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_song = df.query(\"Singer == 'darude'\")\n",
    "bad_song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(axis=0, index=bad_song.index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add midi files' names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_midi_files(df):\n",
    "    midis = list(os.listdir(r'./datasets/midi_files'))\n",
    "    midis = {midi.lower()[:-4]: midi for midi in midis}    \n",
    "    \n",
    "    def combine_singer_song(singer, song):\n",
    "        key = f'{singer} - {song}'.replace(' ', '_').lower()\n",
    "        return midis[key] if key in midis else None\n",
    "    \n",
    "    df['Midi File'] = df.apply(lambda r: combine_singer_song(r['Singer'], r['Song Name']) ,axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_midi_files(df)\n",
    "df_test = add_midi_files(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check midi files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(619,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "midis = np.concatenate([df['Midi File'].values, df_test['Midi File'].values])\n",
    "midis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liavba/.conda/envs/liav_env/lib/python3.7/site-packages/pretty_midi/pretty_midi.py:101: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not decode key with 16 sharps and mode 1\n",
      "error readying midi file David_Bowie_-_Lazarus.mid\n",
      "Could not decode key with 1 flats and mode 255\n",
      "error readying midi file Beastie_Boys_-_Girls.mid\n",
      "data byte must be in range 0..127\n",
      "error readying midi file Billy_Joel_-_Movin'_Out.mid\n",
      "data byte must be in range 0..127\n",
      "error readying midi file Billy_Joel_-_Pressure.mid\n",
      "Could not decode key with 4 flats and mode 255\n",
      "error readying midi file Dan_Fogelberg_-_Leader_of_the_Band.mid\n",
      "\n",
      "error readying midi file Brian_McKnight_-_On_The_Down_Low.mid\n",
      "data byte must be in range 0..127\n",
      "error readying midi file Aaron_Neville_-_Tell_It_Like_It_Is.mid\n"
     ]
    }
   ],
   "source": [
    "corrupted = []\n",
    "for i, midi in enumerate(midis):\n",
    "    try:\n",
    "        midi = pretty_midi.PrettyMIDI(fr'./datasets/midi_files/{midi}')\n",
    "        midi.remove_invalid_notes()\n",
    "        del midi\n",
    "    except Exception as e:\n",
    "        print(\"%s\\nerror readying midi file %s\" % (e, midi))\n",
    "        corrupted.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Singer</th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Midi File</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>david bowie</td>\n",
       "      <td>lazarus</td>\n",
       "      <td>look up here i'm in heaven &amp; i've got scars th...</td>\n",
       "      <td>David_Bowie_-_Lazarus.mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>beastie boys</td>\n",
       "      <td>girls</td>\n",
       "      <td>girls all i really want is girls &amp; and in the ...</td>\n",
       "      <td>Beastie_Boys_-_Girls.mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>billy joel</td>\n",
       "      <td>movin' out</td>\n",
       "      <td>anthony works in the grocery store   &amp; savin h...</td>\n",
       "      <td>Billy_Joel_-_Movin'_Out.mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>billy joel</td>\n",
       "      <td>pressure</td>\n",
       "      <td>you have to learn to pace yourself &amp; pressure ...</td>\n",
       "      <td>Billy_Joel_-_Pressure.mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>dan fogelberg</td>\n",
       "      <td>leader of the band</td>\n",
       "      <td>an only child alone and wild a cabinet maker's...</td>\n",
       "      <td>Dan_Fogelberg_-_Leader_of_the_Band.mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>brian mcknight</td>\n",
       "      <td>on the down low</td>\n",
       "      <td>maxine was 5'9'' &amp; had a man and she didn't mi...</td>\n",
       "      <td>Brian_McKnight_-_On_The_Down_Low.mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>aaron neville</td>\n",
       "      <td>tell it like it is</td>\n",
       "      <td>if you want something to play with &amp; go and fi...</td>\n",
       "      <td>Aaron_Neville_-_Tell_It_Like_It_Is.mid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Singer           Song Name  \\\n",
       "91      david bowie             lazarus   \n",
       "115    beastie boys               girls   \n",
       "136      billy joel          movin' out   \n",
       "143      billy joel            pressure   \n",
       "189   dan fogelberg  leader of the band   \n",
       "513  brian mcknight     on the down low   \n",
       "575   aaron neville  tell it like it is   \n",
       "\n",
       "                                                Lyrics  \\\n",
       "91   look up here i'm in heaven & i've got scars th...   \n",
       "115  girls all i really want is girls & and in the ...   \n",
       "136  anthony works in the grocery store   & savin h...   \n",
       "143  you have to learn to pace yourself & pressure ...   \n",
       "189  an only child alone and wild a cabinet maker's...   \n",
       "513  maxine was 5'9'' & had a man and she didn't mi...   \n",
       "575  if you want something to play with & go and fi...   \n",
       "\n",
       "                                  Midi File  \n",
       "91                David_Bowie_-_Lazarus.mid  \n",
       "115                Beastie_Boys_-_Girls.mid  \n",
       "136             Billy_Joel_-_Movin'_Out.mid  \n",
       "143               Billy_Joel_-_Pressure.mid  \n",
       "189  Dan_Fogelberg_-_Leader_of_the_Band.mid  \n",
       "513    Brian_McKnight_-_On_The_Down_Low.mid  \n",
       "575  Aaron_Neville_-_Tell_It_Like_It_Is.mid  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_songs = df.iloc[corrupted]\n",
    "bad_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(axis=0, index=bad_songs.index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = np.random.rand(len(df)) < 0.8\n",
    "\n",
    "df_train = df[msk]\n",
    "df_val = df[~msk]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lyrics preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    phrase = re.sub(r\"in\\'\", \"ing\", phrase)\n",
    "    phrase = re.sub(r\"y\\'all\", \"you all\", phrase)\n",
    "    phrase = re.sub(r\"hiya\", \"hi you\", phrase)\n",
    "    \n",
    "    # punctions\n",
    "    regex = re.compile('[^a-zA-Z& ]')\n",
    "    phrase = regex.sub('', phrase)\n",
    "    \n",
    "    return phrase\n",
    "\n",
    "def preprocess_lyrics(data):\n",
    "    data = decontracted(data)\n",
    "    tokens = word_tokenize(data)\n",
    "    data_arr = []\n",
    "    \n",
    "    for t in tokens:\n",
    "        # Use only words, character combinations and numbers \n",
    "#         if not t.isalpha(): \n",
    "#             continue\n",
    "            \n",
    "        # Lower case word\n",
    "        t = t.lower()\n",
    "        \n",
    "#         # Remove stop words\n",
    "#         if t in sw: \n",
    "#             continue\n",
    "        \n",
    "        data_arr.append(t)\n",
    "    \n",
    "    \n",
    "    return data_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"you know i need your love & you've got that hold over me & long as i've got your love & you know that i'll never leave & when i wanted you to share my life & i had no doubt in my mind & and it's been you woman & right down the line & i know how much i lean on you & only you can see & the changes that i've been through & have left a mark on me & you've been as constant as a northern star & the brightest light that shines & it's been you woman right down the line & i just want to say this is my way & of tellin' you everything & i could never say before & yeah this is my way of tellin' you & that every day i'm lovin' you so much more & 'cause you believed in me through my darkest night & put somethin' better inside of me & you brought me into the light & threw away all those crazy dreams & i put them all behind & and it was you woman & right down the line & i just want to say this is my way of tellin' you everything & i could never say before & yeah this is my way of tellin' you & everything i could never say before & yeah this is my way of tellin' you & that every day i'm lovin' you so much more &\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.iloc[1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you know i need your love \n",
      "\n",
      "you have got that hold over me \n",
      "\n",
      "long as i have got your love \n",
      "\n",
      "you know that i will never leave \n",
      "\n",
      "when i wanted you to share my life \n",
      "\n",
      "i had no doubt in my mind \n",
      "\n",
      "and it is been you woman \n",
      "\n",
      "right down the line \n",
      "\n",
      "i know how much i lean on you \n",
      "\n",
      "only you can see \n",
      "\n",
      "the changes that i have been through \n",
      "\n",
      "have left a mark on me \n",
      "\n",
      "you have been as constant as a northern star \n",
      "\n",
      "the brightest light that shines \n",
      "\n",
      "it is been you woman right down the line \n",
      "\n",
      "i just want to say this is my way \n",
      "\n",
      "of telling you everything \n",
      "\n",
      "i could never say before \n",
      "\n",
      "yeah this is my way of telling you \n",
      "\n",
      "that every day i am loving you so much more \n",
      "\n",
      "cause you believed in me through my darkest night \n",
      "\n",
      "put something better inside of me \n",
      "\n",
      "you brought me into the light \n",
      "\n",
      "threw away all those crazy dreams \n",
      "\n",
      "i put them all behind \n",
      "\n",
      "and it was you woman \n",
      "\n",
      "right down the line \n",
      "\n",
      "i just want to say this is my way of telling you everything \n",
      "\n",
      "i could never say before \n",
      "\n",
      "yeah this is my way of telling you \n",
      "\n",
      "everything i could never say before \n",
      "\n",
      "yeah this is my way of telling you \n",
      "\n",
      "that every day i am loving you so much more \n",
      "\n"
     ]
    }
   ],
   "source": [
    "string = df_train.iloc[1,2]\n",
    "tokenized_string = preprocess_lyrics(string)\n",
    "\n",
    "def pretty_lyrics(tokenized_string):\n",
    "    for token in tokenized_string:\n",
    "        if token == '&':\n",
    "            print('\\n')\n",
    "        else:\n",
    "            print(token, end=' ')\n",
    "\n",
    "pretty_lyrics(tokenized_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_token = '$'\n",
    "lyrics_train = df_train['Lyrics'].apply(lambda s: preprocess_lyrics(s)[:-1] + [stop_token])\n",
    "lyrics_val = df_val['Lyrics'].apply(lambda s: preprocess_lyrics(s)[:-1] + [stop_token])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(lyrics_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_train = tokenizer.texts_to_sequences(lyrics_train)\n",
    "lyrics_val = tokenizer.texts_to_sequences(lyrics_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_FILE = './GoogleNews-vectors-negative300.bin'\n",
    "\n",
    "if not os.path.isfile(EMBEDDING_FILE):\n",
    "    !wget -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\"\n",
    "    !gzip -f -d GoogleNews-vectors-negative300.bin.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "414 out of 6160 has no embedings from word2vec\n"
     ]
    }
   ],
   "source": [
    "from gensim import models\n",
    "\n",
    "embeddings_index = models.KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)\n",
    "embed_size = 300\n",
    "word_index = tokenizer.word_index\n",
    "max_features = len(word_index) + 1\n",
    "\n",
    "nb_words = len(word_index)\n",
    "embedding_matrix = (np.random.rand(nb_words+1, embed_size) - 0.5) / 5.0\n",
    "\n",
    "not_in_word2vec = 0\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    if word in embeddings_index:\n",
    "        embedding_vector = embeddings_index.get_vector(word)\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    else:\n",
    "        not_in_word2vec += 1\n",
    "        \n",
    "print(f'{not_in_word2vec} out of {len(word_index)} has no embedings from word2vec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying one word to whole song but one word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x, train_y = [], []\n",
    "\n",
    "# for lyric in lyrics:\n",
    "#     for i in range(1, len(lyric)):\n",
    "#         train_x.append(lyric[:i])\n",
    "#         train_y.append(*lyric[i:i+1])\n",
    "        \n",
    "# train_x = pad_sequences(train_x)\n",
    "# train_y = to_categorical(train_y)\n",
    "# train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying sliding window of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ast=np.lib.index_tricks.as_strided\n",
    "def generate_sliding_window(arr, window_size=5, window_stride=1, last_window=False):\n",
    "    last_window = 1 if last_window else 0\n",
    "    arr = np.ascontiguousarray(arr)\n",
    "    arr_len = arr.shape[0]\n",
    "    s, = arr.strides\n",
    "    windows_num = ((arr_len-window_size)//window_stride) + last_window\n",
    "    \n",
    "    return ast(arr, (windows_num, window_size), (s*window_stride, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_lyrics(lyrics, window_size=10):\n",
    "    X, y = [], []\n",
    "    for lyric in lyrics:\n",
    "        X.append(generate_sliding_window(lyric, window_size))\n",
    "        y.append(to_categorical(lyric[window_size:], num_classes=max_features))\n",
    "        \n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 10\n",
    "lyrics_train = split_lyrics(lyrics_train, window_size)\n",
    "lyrics_val = split_lyrics(lyrics_val, window_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Melody preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ast=np.lib.index_tricks.as_strided\n",
    "def generate_sliding_window_2d(arr, window_size=5, window_stride=1, last_window=False):\n",
    "    last_window = 1 if last_window else 0\n",
    "    arr = np.ascontiguousarray(arr)\n",
    "    l0, l1 = arr.shape\n",
    "    s0, s1 = arr.strides\n",
    "    windows_num = ((l0-window_size)//window_stride) + last_window\n",
    "    \n",
    "    return ast(arr, (windows_num, window_size, l1), (s0*window_stride, s0, s1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_melody_file_by_time(midi_name, fs=5, max_piano_val=100, fpw=4, window_size=10):\n",
    "    pm = pretty_midi.PrettyMIDI(fr'./datasets/midi_files/{midi_name}')\n",
    "    pm.remove_invalid_notes()\n",
    "    \n",
    "    # Sum all notes from all instruments\n",
    "    piano_all = pm.get_piano_roll(fs=fs)\n",
    "    piano_shape = piano_all.shape\n",
    "\n",
    "    # Normalize by the number of played instruments in the same time and note\n",
    "    counter = np.zeros(piano_shape)\n",
    "    for inst in pm.instruments:\n",
    "        curr_piano = inst.get_piano_roll(fs=fs)\n",
    "\n",
    "        counter[:, :curr_piano.shape[1]] += (curr_piano > 0).astype(int)\n",
    "\n",
    "    counter[counter == 0] = 1\n",
    "    piano_all /= counter\n",
    "    \n",
    "    # Normalize by the maximum value of a note\n",
    "    piano_all = piano_all / max_piano_val\n",
    "    \n",
    "    # Normalize by the number of played notes in the same time\n",
    "    count_notes = (piano_all > 0).sum(axis=0)\n",
    "    count_notes[count_notes == 0] = 1\n",
    "    melody = piano_all.sum(axis=0) / count_notes\n",
    "    del piano_all\n",
    "    \n",
    "    # 3 frames of 5fps equal to 0.6s ~ about one word\n",
    "    melody_per_word = generate_sliding_window(melody[(melody > 0).argmax():], window_size=fpw, window_stride=(fpw*2)//5, last_window=True)\n",
    "    melody_windows = generate_sliding_window_2d(melody_per_word, window_size=window_size, last_window=True)\n",
    "    \n",
    "    return melody_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_melody_file_by_note(midi_name, fs=5, max_piano_val=100):\n",
    "    pm = pretty_midi.PrettyMIDI(fr'./datasets/midi_files/{midi_name}')\n",
    "    pm.remove_invalid_notes()\n",
    "    \n",
    "    # Sum all notes from all instruments\n",
    "    piano_all = pm.get_piano_roll(fs=fs)\n",
    "    piano_shape = piano_all.shape\n",
    "\n",
    "    # Normalize by the number of played instruments in the same time and note\n",
    "    counter = np.zeros(piano_shape)\n",
    "    for inst in pm.instruments:\n",
    "        curr_piano = inst.get_piano_roll(fs=fs)\n",
    "\n",
    "        counter[:, :curr_piano.shape[1]] += (curr_piano > 0).astype(int)\n",
    "\n",
    "    counter[counter == 0] = 1\n",
    "    piano_all /= counter\n",
    "    \n",
    "    # Normalize by the maximum value of a note\n",
    "    piano_all = piano_all / max_piano_val\n",
    "    \n",
    "    # Normalize by the number of played notes in the same time\n",
    "    count_notes = (piano_all > 0).sum(axis=1)\n",
    "    count_notes[count_notes == 0] = 1\n",
    "    melody = piano_all.sum(axis=1) / count_notes\n",
    "    \n",
    "    return melody\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liavba/.conda/envs/liav_env/lib/python3.7/site-packages/ipykernel_launcher.py:7: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5acfbeb1e15941aeb2f814bcdcdaeb0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/612 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liavba/.conda/envs/liav_env/lib/python3.7/site-packages/pretty_midi/pretty_midi.py:101: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-3ac1f3481ae2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmax_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmidi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmidis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mpm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretty_midi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPrettyMIDI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mfr'./datasets/midi_files/{midi}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove_invalid_notes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/liav_env/lib/python3.7/site-packages/pretty_midi/pretty_midi.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, midi_file, resolution, initial_tempo)\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmidi_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0;31m# If a string was given, pass it as the string filename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                 \u001b[0mmidi_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmido\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMidiFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmidi_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0;31m# Otherwise, try passing it in as a file pointer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/liav_env/lib/python3.7/site-packages/mido/midifiles/midifiles.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, file, type, ticks_per_beat, charset, debug, clip)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_track\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/liav_env/lib/python3.7/site-packages/mido/midifiles/midifiles.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(self, infile)\u001b[0m\n\u001b[1;32m    351\u001b[0m                 self.tracks.append(read_track(infile,\n\u001b[1;32m    352\u001b[0m                                               \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m                                               clip=self.clip))\n\u001b[0m\u001b[1;32m    354\u001b[0m                 \u001b[0;31m# TODO: used to ignore EOFError. I hope things still work.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/liav_env/lib/python3.7/site-packages/mido/midifiles/midifiles.py\u001b[0m in \u001b[0;36mread_track\u001b[0;34m(infile, debug, clip)\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_sysex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus_byte\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpeek_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mtrack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/liav_env/lib/python3.7/site-packages/mido/midifiles/midifiles.py\u001b[0m in \u001b[0;36mread_message\u001b[0;34m(infile, status_byte, peek_data, delta, clip)\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data byte must be in range 0..127'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mMessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstatus_byte\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/liav_env/lib/python3.7/site-packages/mido/messages/messages.py\u001b[0m in \u001b[0;36mfrom_bytes\u001b[0;34m(cl, data, time)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \"\"\"\n\u001b[1;32m    123\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mmsgdict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'data'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmsgdict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mmsgdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSysexData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsgdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/liav_env/lib/python3.7/site-packages/mido/messages/decode.py\u001b[0m in \u001b[0;36mdecode_message\u001b[0;34m(msg_bytes, time, check)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_SPECIAL_CASES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstatus_byte\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_decode_data_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus_byte\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/liav_env/lib/python3.7/site-packages/mido/messages/decode.py\u001b[0m in \u001b[0;36m_decode_data_bytes\u001b[0;34m(status_byte, data, spec)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m# TODO: better name than args?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'value_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'channel'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstatus_byte\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mCHANNEL_MESSAGES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "midis = np.concatenate([df['Midi File'].values, df_test['Midi File'].values])\n",
    "fs = 5\n",
    "\n",
    "max_note_val = -1\n",
    "min_frames = 9999\n",
    "max_frames = -1\n",
    "for midi in tqdm(midis):\n",
    "    pm = pretty_midi.PrettyMIDI(fr'./datasets/midi_files/{midi}')\n",
    "    pm.remove_invalid_notes()\n",
    "    \n",
    "    piano_roll = pm.get_piano_roll(fs=fs)\n",
    "    if piano_roll.shape[1]:\n",
    "        curr_len = piano_roll.shape[1]\n",
    "        min_frames = min(min_frames, curr_len)\n",
    "        max_frames = max(max_frames, curr_len)\n",
    "        \n",
    "    for inst in pm.instruments:\n",
    "        piano_roll = inst.get_piano_roll(fs=fs)\n",
    "        if piano_roll.shape[1]:\n",
    "            curr_max_note = piano_roll.max()\n",
    "            max_note_val = max(max_note_val, curr_max_note)\n",
    "        \n",
    "    del pm\n",
    "\n",
    "print(f'The maximum note value is {max_note_val}')\n",
    "print(f'The minimum song length is {min_frames}')\n",
    "print(f'The maximum song length is {max_frames}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-40a4abc4f3db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmelody_train_slided\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Midi File'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess_melody_file_by_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_piano_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m762\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmelody_val_slided\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Midi File'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess_melody_file_by_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_piano_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m762\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/liav_env/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4136\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4137\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4138\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/liav_env/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   4121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4122\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4123\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4125\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-d57443c9fa3f>\u001b[0m in \u001b[0;36mpreprocess_melody_file_by_time\u001b[0;34m(midi_name, fs, max_piano_val, fpw, window_size)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Sum all notes from all instruments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mpiano_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_piano_roll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mpiano_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpiano_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/liav_env/lib/python3.7/site-packages/pretty_midi/pretty_midi.py\u001b[0m in \u001b[0;36mget_piano_roll\u001b[0;34m(self, fs, times, pedal_threshold)\u001b[0m\n\u001b[1;32m    786\u001b[0m         piano_rolls = [i.get_piano_roll(fs=fs, times=times,\n\u001b[1;32m    787\u001b[0m                                         pedal_threshold=pedal_threshold)\n\u001b[0;32m--> 788\u001b[0;31m                        for i in self.instruments]\n\u001b[0m\u001b[1;32m    789\u001b[0m         \u001b[0;31m# Allocate piano roll,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0;31m# number of columns is max of # of columns in all piano rolls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/liav_env/lib/python3.7/site-packages/pretty_midi/pretty_midi.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    786\u001b[0m         piano_rolls = [i.get_piano_roll(fs=fs, times=times,\n\u001b[1;32m    787\u001b[0m                                         pedal_threshold=pedal_threshold)\n\u001b[0;32m--> 788\u001b[0;31m                        for i in self.instruments]\n\u001b[0m\u001b[1;32m    789\u001b[0m         \u001b[0;31m# Allocate piano roll,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0;31m# number of columns is max of # of columns in all piano rolls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/liav_env/lib/python3.7/site-packages/pretty_midi/instrument.py\u001b[0m in \u001b[0;36mget_piano_roll\u001b[0;34m(self, fs, times, pedal_threshold)\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0mbent_roll\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbend_int\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpiano_roll\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbend_int\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbend_range\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                     \u001b[0mbent_roll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpiano_roll\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbend_range\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m                 bent_roll[:-1] = ((1 - bend_decimal)*bent_roll[:-1] +\n\u001b[1;32m    181\u001b[0m                                   bend_decimal*bent_roll[1:])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "melody_train_slided = df_train['Midi File'].apply(preprocess_melody_file_by_time, fs=100, max_piano_val=762, fpw=100, window_size=10)\n",
    "melody_val_slided = df_val['Midi File'].apply(preprocess_melody_file_by_time, fs=100, max_piano_val=762, fpw=100, window_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "melody_train_simple = df_train['Midi File'].apply(preprocess_melody_file_by_note, fs=100, max_piano_val=762)\n",
    "melody_val_simple = df_val['Midi File'].apply(preprocess_melody_file_by_note, fs=100, max_piano_val=762)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_x_y_note(lyrics, melody):\n",
    "    for i in range(len(lyrics[0])):\n",
    "        window_n, window_size = lyrics[0][i].shape\n",
    "        \n",
    "        melody.iloc[i] = np.repeat([melody.iloc[i]], repeats=window_n * window_size).reshape(window_n, window_size, -1)\n",
    "        \n",
    "            \n",
    "    lyrics_X = np.concatenate(lyrics[0])\n",
    "    lyrics_y = np.concatenate(lyrics[1])\n",
    "    melody = np.concatenate(melody.values)\n",
    "            \n",
    "    return (melody, lyrics_X), lyrics_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_simple = prepare_x_y_note(lyrics_train, melody_train_simple)\n",
    "val_data_simple = prepare_x_y_note(lyrics_val, melody_val_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_x_y_time(lyrics, melody):\n",
    "    for i in range(len(lyrics[0])):\n",
    "        mel_len = melody.iloc[i].shape[0]\n",
    "        lyr_len = lyrics[0][i].shape[0]\n",
    "        \n",
    "        if mel_len >= lyr_len:\n",
    "            melody.iloc[i] = melody.iloc[i][:lyr_len, :, :]\n",
    "        else:\n",
    "            lyrics[0][i] = lyrics[0][i][:mel_len, :]\n",
    "            lyrics[1][i] = lyrics[1][i][:mel_len, :]\n",
    "            \n",
    "    lyrics_X = np.concatenate(lyrics[0])\n",
    "    lyrics_y = np.concatenate(lyrics[1])\n",
    "    del lyrics\n",
    "    melody = np.concatenate(melody.values)\n",
    "            \n",
    "    return (melody, lyrics_X), lyrics_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_slided = prepare_x_y(lyrics_train, melody_train_slided)\n",
    "val_data_slided = prepare_x_y(lyrics_val, melody_val_slided)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Lyrics Generator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(window_size, melody_features):\n",
    "    input_melody = Input(shape=(window_size, melody_features), name='melody')\n",
    "    input_lyrics = Input(shape=(window_size,), name='lyrics')\n",
    "    \n",
    "    embd_lyrics = Embedding(max_features, \n",
    "                      embed_size, \n",
    "                      weights=[embedding_matrix],\n",
    "                      input_length=window_size,\n",
    "                      name='word_embd')(input_lyrics)\n",
    "    \n",
    "    merged = Concatenate(axis=2, name='merge')([embd_lyrics, input_melody])\n",
    "    \n",
    "    lstm = LSTM(100, return_sequences=True, dropout=0.5)(merged)\n",
    "    lstm = LSTM(100, dropout=0.5)(lstm)\n",
    "\n",
    "    X = Dense(100, activation=\"relu\")(lstm)\n",
    "    X = Dropout(0.5)(X)\n",
    "    out = Dense(max_features, activation=\"softmax\", name = 'out')(X)\n",
    "\n",
    "    model = Model([input_melody, input_lyrics], out)\n",
    "    \n",
    "#     model.get_layer('embd').trainable = False\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "lyrics (InputLayer)             [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "word_embd (Embedding)           (None, 10, 300)      1848300     lyrics[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "melody (InputLayer)             [(None, 10, 100)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge (Concatenate)             (None, 10, 400)      0           word_embd[0][0]                  \n",
      "                                                                 melody[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 10, 100)      200400      merge[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 100)          80400       lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 100)          10100       lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 100)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "out (Dense)                     (None, 6161)         622261      dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,761,461\n",
      "Trainable params: 2,761,461\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = init_model(10,100)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_simple(seq_len):\n",
    "    inp = Input(shape=(seq_len,))\n",
    "    \n",
    "    embd = Embedding(max_features, \n",
    "                      embed_size, \n",
    "                      weights=[embedding_matrix],\n",
    "                      input_length=seq_len,\n",
    "                      name='word_embd')(inp)\n",
    "    \n",
    "    lstm = LSTM(100, return_sequences=True)(embd)\n",
    "    lstm = LSTM(100)(lstm)\n",
    "\n",
    "    X = Dense(100, activation=\"relu\")(lstm)\n",
    "    X = Dropout(0.5)(X)\n",
    "    out = Dense(max_features, activation=\"softmax\", name = 'out')(X)\n",
    "\n",
    "    model = Model(inp, out)\n",
    "    \n",
    "#     model.get_layer('embd').trainable = False\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callbacks(model_name):\n",
    "    acc = 'val_loss'\n",
    "    acc_mode = 'min'\n",
    "    \n",
    "    checkpoint = ModelCheckpoint(\n",
    "                              fr'./models/{model_name}.h5', \n",
    "                              monitor=acc, \n",
    "#                               verbose=1, \n",
    "                              save_best_only=True, \n",
    "                              mode=acc_mode)\n",
    "    earlystop = EarlyStopping(monitor=acc, mode=acc_mode, verbose=1, patience=6)\n",
    "    reduceLR = ReduceLROnPlateau(monitor = 'val_loss', mode = 'min', patience = 5,\n",
    "                            factor = 0.5, min_lr = 1e-6, verbose = 1)\n",
    "\n",
    "    return [checkpoint, reduceLR, earlystop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_name, model_gen, train_data, val_data, use_saved=False, params_dict=None):\n",
    "    os.makedirs('./models', exist_ok=True)\n",
    "    params = ''\n",
    "    if params_dict is not None:\n",
    "        params = '_'.join(f'{key}_{val}' for key,val in params_dict.items())\n",
    "    model_name = model_gen.__name__[5:] + f'_{model_name}' + f'_{params}'\n",
    "        \n",
    "    if use_saved:\n",
    "        history = joblib.load(fr'./models/{model_name}_history.sav')\n",
    "    else:\n",
    "        callbacks = get_callbacks(model_name)\n",
    "        \n",
    "        train_x, train_y = train_data\n",
    "        \n",
    "        model = model_gen(*train_x[0].shape[1:]) # melody size\n",
    "        history = model.fit(\n",
    "                            x=train_x,\n",
    "                            y=train_y,\n",
    "                            batch_size=params_dict['batch_size'],\n",
    "                            epochs=params_dict['epochs'],\n",
    "                            validation_data=val_data,\n",
    "                            callbacks=callbacks,\n",
    "                            verbose=1\n",
    "                            )\n",
    "        \n",
    "        history = history.history\n",
    "        joblib.dump(history, fr'./models/{model_name}_history.sav')\n",
    "    \n",
    "    model = load_model(fr'./models/{model_name}.h5')\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-91ad55d33b41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_x' is not defined"
     ]
    }
   ],
   "source": [
    "model = init_simple(train_x.shape[1])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "init_simple() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-6ce98d5572e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mparams_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'epochs'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_simple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_saved\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-68-5ae0739cef4e>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model_gen, train_data, val_data, use_saved, params_dict)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# melody size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         history = model.fit(\n\u001b[1;32m     17\u001b[0m                             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: init_simple() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "params_dict = {'batch_size': 32, 'epochs': 5}\n",
    "model, history= train_model(init_simple, train_data, val_data, use_saved=False, params_dict=params_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4499/4499 [==============================] - 81s 16ms/step - loss: 5.8421 - val_loss: 5.0701\n",
      "Epoch 2/20\n",
      "4499/4499 [==============================] - 66s 15ms/step - loss: 5.1992 - val_loss: 4.8369\n",
      "Epoch 3/20\n",
      "4499/4499 [==============================] - 77s 17ms/step - loss: 4.9348 - val_loss: 4.7561\n",
      "Epoch 4/20\n",
      "4499/4499 [==============================] - 77s 17ms/step - loss: 4.7859 - val_loss: 4.7425\n",
      "Epoch 5/20\n",
      "4499/4499 [==============================] - 77s 17ms/step - loss: 4.6453 - val_loss: 4.7311\n",
      "Epoch 6/20\n",
      "4499/4499 [==============================] - 77s 17ms/step - loss: 4.5675 - val_loss: 4.7332\n",
      "Epoch 7/20\n",
      "4499/4499 [==============================] - 77s 17ms/step - loss: 4.4905 - val_loss: 4.7547\n",
      "Epoch 8/20\n",
      "4499/4499 [==============================] - 77s 17ms/step - loss: 4.4507 - val_loss: 4.7531\n",
      "Epoch 9/20\n",
      "4499/4499 [==============================] - 77s 17ms/step - loss: 4.3979 - val_loss: 4.7887\n",
      "Epoch 10/20\n",
      "4499/4499 [==============================] - 77s 17ms/step - loss: 4.3398 - val_loss: 4.7869\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 11/20\n",
      "4499/4499 [==============================] - 77s 17ms/step - loss: 4.2993 - val_loss: 4.7792\n",
      "Epoch 00011: early stopping\n"
     ]
    }
   ],
   "source": [
    "params_dict = {'batch_size': 32, 'epochs': 20}\n",
    "model, history= train_model('whole', init_model, train_data_simple, val_data_simple, use_saved=False, params_dict=params_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4273/4273 [==============================] - 75s 17ms/step - loss: 5.8492 - val_loss: 5.0854\n",
      "Epoch 2/20\n",
      "4273/4273 [==============================] - 60s 14ms/step - loss: 5.2188 - val_loss: 4.8665\n",
      "Epoch 3/20\n",
      "4273/4273 [==============================] - 72s 17ms/step - loss: 4.9603 - val_loss: 4.7791\n",
      "Epoch 4/20\n",
      "4273/4273 [==============================] - 72s 17ms/step - loss: 4.7815 - val_loss: 4.7518\n",
      "Epoch 5/20\n",
      "4273/4273 [==============================] - 72s 17ms/step - loss: 4.6575 - val_loss: 4.7285\n",
      "Epoch 6/20\n",
      "4273/4273 [==============================] - 72s 17ms/step - loss: 4.5703 - val_loss: 4.7296\n",
      "Epoch 7/20\n",
      "4273/4273 [==============================] - 72s 17ms/step - loss: 4.4919 - val_loss: 4.7443\n",
      "Epoch 8/20\n",
      "4273/4273 [==============================] - 72s 17ms/step - loss: 4.4269 - val_loss: 4.7891\n",
      "Epoch 9/20\n",
      "4273/4273 [==============================] - 72s 17ms/step - loss: 4.3919 - val_loss: 4.7714\n",
      "Epoch 10/20\n",
      "4273/4273 [==============================] - 72s 17ms/step - loss: 4.3204 - val_loss: 4.7721\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 11/20\n",
      "4273/4273 [==============================] - 72s 17ms/step - loss: 4.2644 - val_loss: 4.8214\n",
      "Epoch 00011: early stopping\n"
     ]
    }
   ],
   "source": [
    "params_dict = {'batch_size': 32, 'epochs': 20}\n",
    "model, history= train_model('slided', init_model, train_data_slided, val_data_slided, use_saved=False, params_dict=params_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Lyrics by Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_song(model, seed, window_size, stop_token, tokenizer, max_len):\n",
    "    stop_token = tokenizer.word_index[stop_token]\n",
    "    \n",
    "    def get_next_word(seed):\n",
    "        probs = model(seed, training=False)\n",
    "        chosen_idx = np.random.choice(range(0, max_features), p=probs[0])\n",
    "        chosen_word = tokenizer.sequences_to_texts([[chosen_idx]])[0]\n",
    "        \n",
    "        return chosen_idx, chosen_word\n",
    "    \n",
    "    \n",
    "    seed = preprocess_lyrics(seed)\n",
    "    song = seed.copy()\n",
    "    seed = ' '.join(seed)\n",
    "    seed = tokenizer.texts_to_sequences([seed])\n",
    "    seed = pad_sequences(seed, maxlen=window_size)\n",
    "\n",
    "    i = 0\n",
    "    idx, word = get_next_word(seed)\n",
    "    while word != stop_token and i < max_len:\n",
    "        song.append(word)\n",
    "        i+=1\n",
    "        seed = np.concatenate([seed[:,1:], [[idx]]], axis=1)\n",
    "        idx, word = get_next_word(seed)\n",
    "    \n",
    "    return song    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_max_length = 2000\n",
    "seed = 'Smack that all on the floor'\n",
    "song = generate_song(model, seed, window_size, stop_token, tokenizer, song_max_length)\n",
    "pretty_lyrics(song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Singer</th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Midi File</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the bangles</td>\n",
       "      <td>eternal flame</td>\n",
       "      <td>close your eyes give me your hand darling &amp; do...</td>\n",
       "      <td>The_Bangles_-_Eternal_Flame.mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>billy joel</td>\n",
       "      <td>honesty</td>\n",
       "      <td>if you search for tenderness &amp; it isn't hard t...</td>\n",
       "      <td>Billy_Joel_-_Honesty.mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cardigans</td>\n",
       "      <td>lovefool</td>\n",
       "      <td>dear i fear we're facing a problem &amp; you love ...</td>\n",
       "      <td>Cardigans_-_Lovefool.mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aqua</td>\n",
       "      <td>barbie girl</td>\n",
       "      <td>hiya barbie &amp; hi ken! &amp; do you want to go for ...</td>\n",
       "      <td>Aqua_-_Barbie_Girl.mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blink 182</td>\n",
       "      <td>all the small things</td>\n",
       "      <td>all the small things &amp; true care truth brings ...</td>\n",
       "      <td>Blink_182_-_All_the_Small_Things.mid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Singer             Song Name  \\\n",
       "0  the bangles         eternal flame   \n",
       "1   billy joel               honesty   \n",
       "2    cardigans              lovefool   \n",
       "3         aqua           barbie girl   \n",
       "4    blink 182  all the small things   \n",
       "\n",
       "                                              Lyrics  \\\n",
       "0  close your eyes give me your hand darling & do...   \n",
       "1  if you search for tenderness & it isn't hard t...   \n",
       "2  dear i fear we're facing a problem & you love ...   \n",
       "3  hiya barbie & hi ken! & do you want to go for ...   \n",
       "4  all the small things & true care truth brings ...   \n",
       "\n",
       "                              Midi File  \n",
       "0       The_Bangles_-_Eternal_Flame.mid  \n",
       "1              Billy_Joel_-_Honesty.mid  \n",
       "2              Cardigans_-_Lovefool.mid  \n",
       "3                Aqua_-_Barbie_Girl.mid  \n",
       "4  Blink_182_-_All_the_Small_Things.mid  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_song_with_melody(model, model_type, lyrics_seed, midi_name, window_size, tokenizer, max_len, fpw=100, stop_token='$'):\n",
    "    stop_token_idx = tokenizer.word_index[stop_token]\n",
    "    if model_type == 'slided':\n",
    "        melody = preprocess_melody_file_by_time(midi_name, fs=100, max_piano_val=762, fpw=fpw, window_size=window_size)\n",
    "    else:\n",
    "        melody = preprocess_melody_file_by_note(midi_name, fs=100, max_piano_val=762)\n",
    "        melody = np.repeat([melody], repeats=window_size, axis=0)\n",
    "        melody = np.expand_dims(melody, axis=0)\n",
    "    \n",
    "    def get_next_word(lyrics_seed, melody_seed):\n",
    "        if melody_seed is None:\n",
    "            return stop_token_idx, stop_token\n",
    "        try:\n",
    "            probs = model((melody_seed, lyrics_seed), training=False)\n",
    "            probs_v = np.array(probs[0])\n",
    "            chosen_idx = np.random.choice(range(0, max_features), p=probs_v)\n",
    "            chosen_word = tokenizer.sequences_to_texts([[chosen_idx]])[0]\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return stop_token_idx, stop_token\n",
    "        \n",
    "        return chosen_idx, chosen_word\n",
    "    \n",
    "    def get_melody_seed(word_cnt):\n",
    "        if model_type == \"whole\":\n",
    "            return melody\n",
    "        \n",
    "        if word_cnt - window_size >= melody.shape[0]:\n",
    "            return None\n",
    "        \n",
    "        if word_cnt < window_size:\n",
    "            melody_seed = np.concatenate([np.zeros((window_size-word_cnt,fpw)),melody[0][:word_cnt,:fpw]])\n",
    "        else:\n",
    "            window_idx = word_cnt-window_size\n",
    "            \n",
    "            if window_idx >= melody.shape[0]: # Melody has ended\n",
    "                return None\n",
    "            \n",
    "            melody_seed = melody[window_idx]\n",
    "        \n",
    "        return np.expand_dims(melody_seed, axis=0)\n",
    "    \n",
    "    \n",
    "    lyrics_seed = preprocess_lyrics(lyrics_seed)\n",
    "    song = lyrics_seed.copy()\n",
    "    lyrics_seed = ' '.join(lyrics_seed)\n",
    "    lyrics_seed = tokenizer.texts_to_sequences([lyrics_seed])\n",
    "    word_cnt = len(lyrics_seed[0])\n",
    "    lyrics_seed = pad_sequences(lyrics_seed, maxlen=window_size)\n",
    "\n",
    "    melody_seed = get_melody_seed(word_cnt)\n",
    "    idx, word = get_next_word(lyrics_seed, melody_seed)\n",
    "    \n",
    "    while idx != stop_token_idx and word_cnt < max_len:\n",
    "        song.append(word)\n",
    "        word_cnt+=1\n",
    "        lyrics_seed = np.concatenate([lyrics_seed[:,1:], [[idx]]], axis=1)\n",
    "        melody_seed = get_melody_seed(word_cnt)\n",
    "        idx, word = get_next_word(lyrics_seed, melody_seed)\n",
    "    \n",
    "    return song    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_gen_song(midi_name, model_type, lyrics_seed,  window_size=10, song_max_length=100,):\n",
    "    print(f'\\n[Song: {midi_name}, seed: {lyrics_seed}]\\n')\n",
    "    song = generate_song_with_melody(model, model_type, lyrics_seed, midi_name, window_size, tokenizer, song_max_length, fpw=100)\n",
    "    pretty_lyrics(song)\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Song: The_Bangles_-_Eternal_Flame.mid, seed: Hello]\n",
      "\n",
      "hello \n",
      "\n",
      "cause the lovesick show come there to time \n",
      "\n",
      "tender ai not all easy i all settle \n",
      "\n",
      "bailamos \n",
      "\n",
      "\n",
      "[Song: Billy_Joel_-_Honesty.mid, seed: Hello]\n",
      "\n",
      "hello \n",
      "\n",
      "nothing lie before \n",
      "\n",
      "baby i believe \n",
      "\n",
      "sentimental thing after summer \n",
      "\n",
      "niggas are when them wrong built lost your inside \n",
      "\n",
      "nothing gets the waking \n",
      "\n",
      "hold some still in an fall we know \n",
      "\n",
      "we are born \n",
      "\n",
      "anyone feels fire with the soldier x \n",
      "\n",
      "the glitter so properly \n",
      "\n",
      "it is the plan we are singing on for an willow bill of by come and happier \n",
      "\n",
      "dont ol nothing me along i will say \n",
      "\n",
      "i am all the eyes day where it is my wan na see \n",
      "\n",
      "do not reach \n",
      "\n",
      "\n",
      "[Song: Cardigans_-_Lovefool.mid, seed: Hello]\n",
      "\n",
      "hello \n",
      "\n",
      "got up on the action and long till good care alone \n",
      "\n",
      "i do not know over oh \n",
      "\n",
      "the invisible could tell me forget here \n",
      "\n",
      "more through we have mine \n",
      "\n",
      "playing so weeks this suppper even shoes \n",
      "\n",
      "but i would gon na all it that kick in my love \n",
      "\n",
      "if i want to say and i am are girl \n",
      "\n",
      "you have be allentown in the survivor \n",
      "\n",
      "look \n",
      "\n",
      "hang up of night \n",
      "\n",
      "twist free safe through your ever ai not time about there \n",
      "\n",
      "come in love gim me \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[Song: Aqua_-_Barbie_Girl.mid, seed: Hello]\n",
      "\n",
      "hello \n",
      "\n",
      "he looks \n",
      "\n",
      "christmas doll \n",
      "\n",
      "and everybody ai not on done i have \n",
      "\n",
      "and i see a ways \n",
      "\n",
      "you took in sunday through very heart \n",
      "\n",
      "put you on one i can see you can ride this summer \n",
      "\n",
      "carry around out in that sea everybody tries to love or other \n",
      "\n",
      "but do you chaka happy now \n",
      "\n",
      "quite a air your foolish house at what you know a hot bit like living out on my world on the reason through little late girl \n",
      "\n",
      "with i feel a rebel night \n",
      "\n",
      "so i \n",
      "\n",
      "\n",
      "[Song: Blink_182_-_All_the_Small_Things.mid, seed: Hello]\n",
      "\n",
      "hello and mister alive \n",
      "\n",
      "i will not get her new \n",
      "\n",
      "i have and \n",
      "\n",
      "on my my he of and post \n",
      "\n",
      "when it i ever there now \n",
      "\n",
      "oh waterloo will the heart and look worse \n",
      "\n",
      "nobody seems loved you go do you walking \n",
      "\n",
      "i make me hurt if you think he is guy you should make it ahead \n",
      "\n",
      "the roof there will never be a trouper goes \n",
      "\n",
      "only lovely body and could love \n",
      "\n",
      "i said all has under the colors but up on your arms \n",
      "\n",
      "believe it to right \n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    None\n",
       "1    None\n",
       "2    None\n",
       "3    None\n",
       "4    None\n",
       "Name: Midi File, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['Midi File'].apply(lambda midi_name: apply_gen_song(midi_name,'whole', 'Hello'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Song: The_Bangles_-_Eternal_Flame.mid, seed: close]\n",
      "\n",
      "close again \n",
      "\n",
      "now the dust reflecting run i more it around \n",
      "\n",
      "girl find my name i want me \n",
      "\n",
      "oh we say you wanted the strong is picking \n",
      "\n",
      "he like i do it do what make the so cash get san park \n",
      "\n",
      "to known that getting \n",
      "\n",
      "still leaves to just make me let me ever help you \n",
      "\n",
      "i know the will such life on where long \n",
      "\n",
      "\n",
      "[Song: Billy_Joel_-_Honesty.mid, seed: if]\n",
      "\n",
      "if i move in after gave \n",
      "\n",
      "on the half is see \n",
      "\n",
      "you come \n",
      "\n",
      "the woman reaches night long down and a rum \n",
      "\n",
      "you still that hanging out and slip the fucking sky \n",
      "\n",
      "never just remember what my it is heaven \n",
      "\n",
      "oh when a running unfurled \n",
      "\n",
      "just hope you can not feed me a take them away \n",
      "\n",
      "just close \n",
      "\n",
      "santa soul with \n",
      "\n",
      "oh it is it up i really know more \n",
      "\n",
      "and nothing song ooh change \n",
      "\n",
      "how never me \n",
      "\n",
      "it is to so too in the set \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[Song: Cardigans_-_Lovefool.mid, seed: dear]\n",
      "\n",
      "dear and rustles \n",
      "\n",
      "she \n",
      "\n",
      "word is around we listen to why \n",
      "\n",
      "and are someone \n",
      "\n",
      "lord you wan na do \n",
      "\n",
      "you wan na go \n",
      "\n",
      "the daddy train to get today \n",
      "\n",
      "in a victim they wan na how see let me two \n",
      "\n",
      "do not never see let me need you \n",
      "\n",
      "this you are that alright that can not will made \n",
      "\n",
      "hey he again but it is ai not a salvation wrong if i will just never when not make a gon na slide with it \n",
      "\n",
      "cause i know is i see \n",
      "\n",
      "\n",
      "[Song: Aqua_-_Barbie_Girl.mid, seed: hiya]\n",
      "\n",
      "hi you am living and school and soon do you do you \n",
      "\n",
      "i should feel em i want to want to stand \n",
      "\n",
      "i love it but there is not the one \n",
      "\n",
      "telling me just my own \n",
      "\n",
      "can not you carry all it is to the ocean \n",
      "\n",
      "the lonely colors ba thousand figure \n",
      "\n",
      "who are times love so while you are here \n",
      "\n",
      "sometimes i see \n",
      "\n",
      "time gets years the old colour repeat like a church to the mountain \n",
      "\n",
      "well you rhythm all a can warm \n",
      "\n",
      "\n",
      "[Song: Blink_182_-_All_the_Small_Things.mid, seed: all]\n",
      "\n",
      "all \n",
      "\n",
      "should taking roller floor tonight \n",
      "\n",
      "i want i know a cruel way \n",
      "\n",
      "think i am meet your dream is \n",
      "\n",
      "kind the her rate i would dust this bow \n",
      "\n",
      "and nothing say of pacing the surrender \n",
      "\n",
      "cause \n",
      "\n",
      "and one diggity i is through far \n",
      "\n",
      "what all my strong day i am no mom \n",
      "\n",
      "when you soon cause i do not laugh \n",
      "\n",
      "i do not fly again \n",
      "\n",
      "but the tragedy and are a shubop bit \n",
      "\n",
      "and to do you called our body \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    None\n",
       "1    None\n",
       "2    None\n",
       "3    None\n",
       "4    None\n",
       "dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.apply(lambda r: apply_gen_song(r['Midi File'], 'whole', r['Lyrics'].split(' ')[0]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "liav_notebook",
   "language": "python",
   "name": "liav_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
